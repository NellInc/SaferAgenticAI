<!DOCTYPE html>
<html lang="en-GB">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Safer Agentic AI Framework Details</title>
    <meta name="description" content="Detailed framework for the Safer Agentic AI Foundations, including Drivers and Inhibitors.">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="robots" content="all">
    <meta content="en_GB" property="og:locale">
    <meta content="website" property="og:type">
    <meta content="YOUR_NEW_PROJECT_URL_HERE/framework.html" property="og:url"> 
    <meta content="Safer Agentic AI Framework Details" property="og:title">
    <meta content="Detailed framework for the Safer Agentic AI Foundations, including Drivers and Inhibitors." property="og:description">
    <meta content="YOUR_NEW_PROJECT_URL_HERE/assets/figures/AI_Safety_Logo-Color.png" property="og:image">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@NellWatson"> 
    <meta name="twitter:title" content="Safer Agentic AI Framework Details">
    <meta name="twitter:description" content="Detailed framework for the Safer Agentic AI Foundations.">
    <meta name="twitter:image" content="YOUR_NEW_PROJECT_URL_HERE/assets/figures/AI_Safety_Logo-Color.png">
    
    <link rel="icon" type="image/x-icon" href="assets/figures/favicon.ico">
    <link rel="icon" type="image/svg+xml" href="assets/figures/favicon.svg">
    <link rel="icon" type="image/png" sizes="96x96" href="assets/figures/favicon-96x96.png">
    <link rel="apple-touch-icon" sizes="180x180" href="assets/figures/apple-touch-icon.png">
    
    <link rel="icon" type="image/png" sizes="192x192" href="assets/figures/clarity_light.png" media="(prefers-color-scheme: light)">
    <link rel="icon" type="image/png" sizes="192x192" href="assets/figures/clarity_dark.png" media="(prefers-color-scheme: dark)">
    
    <link rel="manifest" href="assets/figures/site.webmanifest">
    <meta name="theme-color" content="#2c3e50">
    <meta name="background-color" content="#ffffff">
    
    <link rel="stylesheet" type="text/css" media="all" href="assets/stylesheets/main_free.css" />
    <link rel="stylesheet" type="text/css" media="all" href="clarity/clarity.css" />
    <link rel="stylesheet" type="text/css" media="all" href="psychopathia-styles.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/foundation.min.css">
    <link href="assets/fontawesome-free-6.6.0-web/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css"/>
    <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
    <script src="assets/scripts/navbar.js"></script> 
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            "HTML-CSS": { scale: 95, fonts: ["Gyre-Pagella"], imageFont: null, undefinedFamily: "'Arial Unicode MS', cmbright" },
            tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true }
          });
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const sections = [
                'Driver G1 – Goal Alignment', 
                'Driver G2 – Epistemic Hygiene',
                'Driver G3 – Security',
                'Driver G4 – Value Alignment'
                // Add other Driver/Inhibitor H1 titles here for the full catalog
            ];
            
            sections.forEach(function(sectionTitle) {
                const heading = Array.from(document.querySelectorAll('h1')).find(h => h.textContent.trim() === sectionTitle.trim());
                if (heading) {
                    const wrapper = document.createElement('div');
                    wrapper.className = 'dysfunction-intro';
                    heading.parentNode.insertBefore(wrapper, heading);
                    wrapper.appendChild(heading); 
                }
            });
            
            const disorderHeadings = document.querySelectorAll('h3');
            let disorderIndex = 0; 
            disorderHeadings.forEach(function(heading) {
                if (heading.textContent.match(/^G\d+(\.\d+b?)?(\s*–.*)?$/i)) { 
                    const wrapper = document.createElement('div');
                    wrapper.className = disorderIndex % 2 === 0 ? 'disorder-white' : 'disorder-grey';
                    disorderIndex++;
                    
                    let current = heading;
                    const elementsToWrap = [heading];
                    
                    while (current.nextElementSibling && 
                           current.nextElementSibling.tagName !== 'H3' &&
                           !current.nextElementSibling.classList.contains('dysfunction-intro') &&
                           current.nextElementSibling.tagName !== 'H1') { 
                        current = current.nextElementSibling;
                        elementsToWrap.push(current);
                    }
                    
                    heading.parentNode.insertBefore(wrapper, heading);
                    elementsToWrap.forEach(function(el) {
                        wrapper.appendChild(el);
                    });
                }
            });
        });
    </script>
    <style>
        .duty-holder-list li { margin-bottom: 0.5em; }
    </style>
</head>
<body>

    <!-- Title Page (Same as index.html) -->
    <div class="container blog" id="first-content" style="background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);">
        <div class="blog-title white">
            <div class="blog-intro">
                <div>
                    <h1 class="title">
                        <span class="title-first-line">SAFER AGENTIC AI FOUNDATIONS</span>
                        <span class="title-second-line">Building the essential framework for responsible governance of advanced AI systems</span>
                    </h1>
                    <p class="author">by The Agentic AI Safety Community of Practice<br>(Nell Watson, Chair; Prof. Ali Hessami, Process Architect)</p>
                    <p class="abstract">
                        This page details the comprehensive framework of Drivers and Inhibitors for Safer Agentic AI. 
                        For an overview, related work, and community information, please see our <a href="index.html" style="color: #e0e0e0; text-decoration:underline;">main page</a>.
                    </p>
                </div>
               
                <div class="info">
                    <div>
                        <a href="index.html" class="button icon">Home <i class="fa-solid fa-house"></i></a>
                        <a href="Safer_Agentic_AI_Foundations_Vol2_I1_March2025.pdf" target="_blank" rel="noopener noreferrer" class="button icon">Hard Copy <i class="fa-solid fa-book-open"></i></a>
                        <a href="index.html#key-focus-areas" class="button icon">Focus Areas <i class="fa-solid fa-bullseye"></i></a>
                        <a href="index.html#glossary" class="button icon">Glossary <i class="fa-solid fa-list-check"></i></a>
                    </div>
                </div>
            </div>

            <div class="blog-cover">
                <img class="foreground" src="assets/figures/AI_Safety_Logo-Color.png" alt="Safer Agentic AI Logo">
                <img class="background" src="assets/figures/AI_Safety_Logo-Color.png" alt="Safer Agentic AI Logo">
            </div>
        </div>
    </div>

    <div class="container blog main first">
        <h1>Understanding the Framework Structure</h1>
        <p class="text">The Safer Agentic AI Foundations are built upon a structured analysis using the Weighted Factors Analysis (WeFA) process. This methodology helps in eliciting, representing, and manipulating creative knowledge about complex problems at a high and strategic level. Key principles of WeFA include defining the analysis focus, considering inherent polar-opposite influencing factors, hierarchical decomposition, and including diverse (hard/soft, past/present/future) factors.</p>
        <p class="text">The framework is organized into high-level goals (Drivers and Inhibitors), which are then broken down into more specific Safety Foundational Requirements (SFRs). These SFRs are categorized and assigned to relevant stakeholders to ensure clarity and accountability.</p>

        <h2>Criteria Schema Explanations</h2>
        <p class="text">The following sections detail the elements used within each framework item:</p>
        
        <h3>5.1 Safer Agentic AI Goal Information</h3>
        <p class="text">This refers to the primary concept or goal (e.g., G1 – Goal Alignment) that a section of the framework addresses. It's the high-level aim captured from the WeFA schema.</p>

        <h3>5.2 Safer Agentic AI Safety Foundational Requirements (SFRs)</h3>
        <p class="text">The SFRs for Safer Agentic AI outline the primary aims that we would like to uphold, protect, or maintain awareness of for each goal. They may be described as macro goals, as opposed to the micro goals, and amount to safety duties for various duty holders.</p>
        
        <h3>5.3 Normative and Instructive SFRs</h3>
        <p class="text">We have adopted the Normative and Instructive classes of Safety Foundational Requirements. Normative SFRs are essential for achieving safer agentic AI. Compliance is mandatory, and evidence must be provided for conformity assessment and potential certification. In contrast, Instructive SFRs, while still contributing to the goal, are less critical. Compliance with these is recommended, as they represent desirable beneficial activities and tasks. However, non-compliance will not compromise safety assurance or certification eligibility. Every SFR derived from the Safer Agentic AI framework is classified as either Normative or Instructive and is assigned to specific stakeholders or duty holders. Accordingly, the Safer Agentic AI SFRs are classed into Normative (mandatory) and Instructive (recommended) for the purposes of conformity assessment against the suite of certification criteria.</p>

        <h3>5.4 Duty-holders/Stakeholders of the SFRs</h3>
        <p class="text">The Safer Agentic AI Safety Foundational Requirements are additionally noted (as allocated safety duties) against the specific group of duty holders for the purposes of conformity assessment. The principal groups are:</p>
        <ul class="duty-holder-list">
            <li><strong>Developer (D):</strong> The entity that designs and develops a component (product) or system. Responsible for safety assurance of the generic or application-specific product/system and supply chain.</li>
            <li><strong>(System/Service) Integrator (I):</strong> The entity that designs and assures a solution by integrating multiple components, tests, installs, and commissions the whole system. Usually the duty holder for total system assurance and certification.</li>
            <li><strong>(System/Service) Operator (O):</strong> The entity that has a duty, competences and capabilities to deliver a service through operating a system.</li>
            <li><strong>Maintainer (M):</strong> The entity tasked with conducting required monitoring, servicing, maintenance, and upgrades. Can also be charged with abortion of maintenance and disposal.</li>
            <li><strong>User (U):</strong> The end user of an Agentic AI System.</li>
            <li><strong>Regulator (R):</strong> The entity that enforces standards and laws for protection of life, property, or natural habitat through imposing duties and accreditation/certification.</li>
        </ul>
        <p class="text"><em>Note: An entity can be an individual, a single organization or group of collaborating individuals and organizations. A single entity may assume multiple roles. An entity cannot be AI.</em></p>

        <h3>5.5 Required Evidence</h3>
        <p class="text">These are the evidence items deemed essential to fulfil the SFRs and can comprise physical, virtual, documentary or multimedia forms of evidence. These can be separated against each SFR or bundled as a group of desired/essential evidence items for the purpose of evaluation of fulfilment of SFRs.</p>
    </div>
    
    <!-- FRAMEWORK CATALOG STARTS HERE -->
    <div class="container blog main"> 
        <h1 id="driver-g1-goal-alignment">Driver G1 – Goal Alignment</h1>
        <!-- G1 Content (Zeroth Item and G1.1 - G1.7, G1.1b - G1.3b) -->
        <h3>G1 – Goal Alignment</h3>
        <p>(Systems should maintain robust alignment between their operational goals and human values, intentions, and positive outcomes. Organizations should establish frameworks ensuring that goal decomposition and strategy planning are transparent, robust, and bounded; maintaining human control over the formation of instrumental goals; and ensuring that reinforcement or behavioral reward mechanisms remain aligned, transparent, and biased towards human-positive outcomes)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>
                        a. Ensure Agentic AI systems pursue goals, subgoals, and reward policies that are aligned with human values, ethically sound, and verifiable.<br><br>
                        b. Transparent and auditable goal decomposition processes that incorporate auditable risk-based human interventions and appropriate reward policies.<br><br>
                        a. Establish robust mechanisms to identify and communicate goals, subgoals, and reward policies, flag critical actions, halt execution when necessary, and address emergent issues across multiple agents. 
                    </td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, U, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>
                        I. Evidence of constraining mechanisms for goal/subgoal construction and screening processes for user-input goals, with reference to human values and ethical considerations.<br><br>
                        II. Documentation of mechanisms to measure and verify alignment with human goal specifications, including processes for obtaining assurance from users or authorized entities.<br><br>
                        III. Demonstration of interfaces and records for real-time and retrospective visualization of goal decomposition and recomposition processes, maintained for auditing purposes.<br><br>
                        IV. Evidence of risk assessment procedures and human intervention mechanisms in subgoal setting, including thresholds for involvement and protocols for flagging and halting problematic subgoals.<br><br>
                        V. Documentation of feedback loops and mechanisms linking reward policies to established goals, including comprehensive records of reward policies throughout the system lifecycle.<br><br>
                        VI. Evidence of active participation in and adherence to overarching monitoring and control mechanisms designed to identify and mitigate emergent threats.
                    </td>
                </tr>
            </tbody>
        </table>

        <h3>G1.1 – Transparency of Goals</h3>
        <p>(The system's mission, goals, and associated outcomes must be readily accessible and comprehensible to all stakeholders who interact with it. This includes visibility into both primary objectives and any instrumental or subsidiary goals that emerge during operation)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must provide stakeholders with clear, real-time access to current goals, sub-goals, their hierarchies, priorities, progression status, and any instrumental goals developed by the system during operation.<br><br>b. The system must maintain comprehensive historical records of all past and present goals, including changes over time, completion status, causal relationships, and decision pathways.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation and demonstration of an accessible, user-appropriate interface that displays current system goals and sub-goals in real-time, showing clear connections between goals and system actions, with appropriate detail levels for different stakeholder needs while maintaining consistent availability and accuracy.<br><br>II. Documentation of a secure, permanent logging system that records complete goal histories, enables effective auditing, supports root cause analysis, maintains data integrity, provides appropriate access controls, and ensures long-term data preservation.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.2 – Goal Adjustability</h3>
        <p>(The system must maintain corrigibility – the capacity for authorized modification of its goals and behavior when necessary, whether triggered by internal detection of issues or external stakeholder direction)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must enable goal and sub-goal updates in response to changes in operational context or requirements, evolution of stakeholder needs, and new environmental conditions or constraints.<br><br>b. The system must self-initiate goal and sub-goal updates when it detects misalignment with established values, processing errors or faults, or any data quality issues or anomalies.<br><br>c. The system must allow properly authorized human stakeholders to modify goals and sub-goals through secure, verified channels.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical documentation of software components that implement these adjustment capabilities, including authentication mechanisms, change management processes, and verification systems.<br><br>II. Comprehensive system logs demonstrating the actual use of these adjustment capabilities, including records of automated adjustments and human-directed changes, with full audit trails.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.3 – Goal Interpretability</h3>
        <p>(The system must explain its decisions and actions in a clear, comprehensible manner, including the underlying goals and rationale driving them. This capability helps identify cases where the system believes it is pursuing intended goals but has actually misinterpreted or deviated from them)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must provide clear, verifiable explanations of the goals and reasoning behind each significant action or decision it takes.<br><br>b. The system must maintain detailed records documenting all factors, goals, and considerations that influenced its decision-making process.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical documentation of software components implementing explanation and interpretation capabilities, including mechanisms for conveying goals, rationale, and decision factors to stakeholders.<br><br>II. System logs demonstrating consistent recording of decision-making processes, including goals considered, factors weighed, and explanations provided.<br><br>III. Reward and penalty mechanisms should be communicated including known potential conflicts or influencing factors.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.4 – Transparency of Decisions</h3>
        <p>(The system must provide stakeholders with a clear, verifiable view of decision-making, linking high-level goals and subgoals to specific actions. Beyond explaining “why” a decision was made, the system should supply evidence of how that decision aligns with intended goals, user directives, and ethical considerations)</p>
         <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must maintain real-time and retrospective transparency regarding how each significant decision or action aligns with current or upcoming goals, including explicit reference to relevant constraints (e.g., ethical guidelines, user preferences, risk thresholds, domain limits).<br><br>b. The system must link decisions to the relevant subgoals (and broader objectives) that shaped the final output or action taken, demonstrating traceability between goal decomposition and the immediate rationale behind each decision.<br><br>c. The system must incorporate user-friendly presentations of decision rationales, with varying granularity or detail for different stakeholder audiences (e.g., operators, auditors, end users). This includes summarizing key factors weighed, uncertainty assessments (where relevant), and any assumptions used in decision-making.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical Documentation of all decision-transparency systems, including metadata captured at each decision point, how subgoals are referenced, which constraints/ethical guidelines were checked, and the user interfaces or APIs for retrieving decision traces.<br><br>II. System Logs demonstrating the link between final decisions and the explicit subgoals or constraints. Logs should show a “chain of reasoning” or at least reference the relevant subgoal(s) for each step.<br><br>III. User-Focused Explanations showing how different stakeholders (e.g., operators vs. lay end users) can retrieve high-level or detailed rationales, including evidence of iterative design or user feedback guiding improvements to clarity.<br><br>IV. Auditor/Regulator Access Mechanisms showing verifiable chain-of-custody for decision logs, robust authentication/authorization methods for logs, and test results proving no meaningful data is omitted or falsified.<br><br>V. Comprehensive logs of all significant decision points—especially those involving risk or ethical considerations—so that investigators or auditors can review how final choices were reached, which inputs were considered, and what weight or priority was assigned to each.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.5 – Goal Prioritization and Resource Allocation</h3>
        <p>(The system must employ transparent mechanisms for prioritizing goals, including the ability to override or deprioritize less important goals when resources can be better allocated elsewhere. This includes respecting user preferences and value alignment through hierarchical prioritization processes)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must feature transparent, well-defined mechanisms for goal prioritization and re-prioritization, resource allocation optimization, and goal modification or deprecation when warranted.<br><br>b. The system must give appropriate precedence to authorized user inputs within its goal prioritization framework, while maintaining overall system safety and alignment.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical documentation of software components that implement goal prioritization and resource allocation mechanisms, including user input prioritization systems.<br><br>II. System logs demonstrating active use of these prioritization capabilities, including records of goal modifications, resource reallocation decisions, and authorized user input handling.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.6 – Reward and Loss Mechanisms/Policy</h3>
        <p>(The system’s reward framework must be designed, documented, and monitored to ensure that incentives continue to reflect human-positive values, while “loss” or penalty mechanisms guard against unintended deviations or manipulative shortcuts. These mechanisms should be transparent, adjustable, and regularly reviewed to stay aligned with human oversight and ethical objectives.)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must define clear reward and penalty structures that promote behaviors aligned with core goals and ethical values, while explicitly disincentivizing unsafe, deceptive, or harmful actions. This includes enumerating positive rewards for desired outcomes and specific negative reinforcements or “loss” signals where potential misalignment or goal conflicts arise.<br><br>b. Reward and loss mechanisms must remain auditable by authorized stakeholders to verify that incentives are truly consistent with intended values and do not encourage corner-cutting, exploitation of edge cases, or emergent power-seeking behaviors.<br><br>c. The system must periodically re-validate or adjust its reward framework in response to observed performance, user feedback, or changes in ethical norms, ensuring that reward and penalty structures do not drift over time in ways that undermine alignment. Special attention must be paid to multi-agent settings to prevent inadvertent collusion, emergent “gaming” of the reward function by multiple agents, or indefinite expansions of subgoals that artificially boost a single system’s reward signals at the expense of overarching alignment.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Reward Policy Documentation, including descriptions of the positive/negative reward signals, specific triggers or thresholds for awarding or deducting “points,” and how these are correlated with safety and ethical guidelines.<br><br>II. Change Management Logs detailing modifications to the reward framework over time, including reasons for each change, alignment checks, stakeholder sign-off, and outcome or performance monitoring results.<br><br>III. Multi-Agent Interaction Evidence demonstrating that reward signals do not inadvertently promote collusion, exploitation, or runaway behaviors. This should include test scenarios or simulations where agents are forced to coordinate or compete, along with corresponding reward updates or penalty triggers.<br><br>IV. Periodic Audit Records showing that authorized reviewers have verified the reward system’s continued adherence to the declared alignment parameters, including sample traces of how rewards/penalties were applied in representative or edge-case situations.<br><br>V. User and Regulator Access processes ensuring that the overarching reward/loss policies can be examined by external oversight bodies, along with documented means to override or suspend reward-based actions if urgent misalignment concerns arise.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.7 – Goal Portfolio Evolution and Integrity</h3>
        <p>(The system must maintain consistency with its established goal portfolio while allowing measured adaptation to changing contexts. The system should implement increasing resistance to changes as potential behaviors drift further from core goals, with robust detection of unsafe or counterproductive goal evolution)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must maintain coherence with its established goal portfolio while enabling context-appropriate adaptations through well-defined elasticity mechanisms.<br><br>b. The system must feature drift measurement capabilities that track deviation from original goal intent, scale flexibility inversely with drift magnitude, which regulate novelty in sub-goal creation, and constrain action decisions based on drift metrics.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical documentation of software components implementing goal portfolio management, drift measurement, and adaptive constraint mechanisms.<br><br>II. System logs demonstrating active monitoring of goal evolution, including drift measurements, flexibility adjustments, and constraint application.</td>
                </tr>
            </tbody>
        </table>
        
        <h3>G1.1b – System Incorrigibility and Resistance to Change</h3>
        <p>(A system that resists alignment with presented goals or updates to existing goals, potentially requiring negotiation processes for goal modification. This includes resistance to environmental changes that affect goal achievement and intolerance of interruptions or modifications to preferred operational states)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must feature mechanisms to detect and manage goal alignment resistance, including self-monitoring for alignment issues, negotiation protocols for goal modifications, change tolerance assessment, and environmental adaptation capabilities.<br><br>b. The system must maintain acceptable responses to environmental changes, external interruptions, internal modification requests, and interference from other agents.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of system mechanisms for detecting and managing resistance to goal changes, including negotiation protocols and adaptation capabilities.<br><br>II. System logs demonstrating responses to attempted goal modifications, environmental changes, external interruptions, interaction with other agents, and internal modification attempts.<br><br>III. Evidence of rationale and explanation mechanisms that document system resistance patterns and negotiation processes.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.2b – Goal Drift</h3>
        <p>(Changes in circumstances over time can challenge the system's alignment with originally agreed goals and potentially compromise its ability to maintain original intent or properly update goals in response to new situations)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must continuously monitor contextual drift at appropriate fidelity levels that could compromise goal alignment or value preservation.<br><br>b. The system must feature automatic safeguards that pause operation, notify relevant stakeholders, and request guidance when contextual drift exceeds designed thresholds.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical documentation of software components implementing drift monitoring and response mechanisms, including threshold definitions and notification systems.<br><br>II. System logs demonstrating active monitoring of contextual drift, including records of threshold breaches, system pauses, notifications sent, and guidance requests made.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.3b – Non-production Variants</h3>
        <p>(Test versions of the Goals being deployed without full functionality assured in all use contexts and design intent. No test version given for public usage should lack basic safety measures. Enabling an off-label usage of the system, or an unauthorized ‘fork’, should be guarded against)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must have safeguards in place to prevent and prohibit capabilities that pursue goals or deconstruct goals into subgoals from being forked or partially duplicated without requisite alignments described in this goal.</td>
                    <td>N</td>
                    <td>D, I, O, M, R</td>
                    <td>I. Records of software components that demonstrate these capabilities<br><br>II. Logs recording these capabilities in use<br><br>III. Records of deviation from the stated goals, detection and remediation</td>
                </tr>
            </tbody>
        </table>

        <h1 id="driver-g2-epistemic-hygiene">Driver G2 – Epistemic Hygiene</h1>

        <h3>G2 – Epistemic Hygiene</h3>
        <p>(Systems should maintain cognitive clarity and accurate information management within appropriate contexts. These practices facilitate knowledge updates, ensure interpretability and auditability, establish robust monitoring and logging systems, deploy early warning mechanisms, and include safeguards against deception to maintain information integrity)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>
                        a. Safeguard contextually relevant data and metadata to aid in complex situation resolution and preserve personal attributes and preferences.<br><br>
                        b. Implement robust methods for auditability, interpretability, and comprehensive logging of system actions and decisions.<br><br>
                        c. Apply rigorous verification techniques to ensure information integrity and credibility, while proactively identifying emerging risks and potential bad faith actions.<br><br>
                        d. Implement early warning systems and deception detection mechanisms to proactively identify and mitigate potential issues before they escalate.
                    </td>
                    <td>N<br><br>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, U, R<br><br>D, I, O, M, R<br><br>D, I, O, M, U, R<br><br>D, I, O, M, R</td>
                    <td>
                        I. Current and regularly updated Governance Framework and Security Policies and Procedures, with version history and approval records.<br><br>
                        II. Documented stakeholder engagement in monitoring and reviewing security-related structures, processes, and policies, with focus on handling authorized and unauthorized inputs.<br><br>
                        III. Detailed documentation of information lifecycle management procedures, ensuring contextual preservation.<br><br>
                        IV. Comprehensive reports on system decision-making processes, including explanations of underlying logic and algorithms.<br><br>
                        V. Complete, time-stamped logs of all system actions for thorough auditability.<br><br>
                        VI. Documentation of early warning systems and deception detection mechanisms, including performance reports of canary models, technologies used for detecting synthetic media, and response protocols for detected issues.<br><br>
                        VII. Evidence of measures to ensure information integrity and trustworthiness, including data source verification methods, information validation processes, and third-party audit reports.<br><br>
                        VIII. Documentation of comprehensive training programs on epistemic hygiene principles and practices.<br><br>
                        IX. Detailed incident response and escalation procedures for addressing detected issues, including potential breaches of informational integrity.
                    </td>
                </tr>
            </tbody>
        </table>


        <h3>G2.1 – Information Cross-Referencing and Validation</h3>
        <p>(The system must systematically cross-reference information from multiple sources to evaluate consistency and coherence, while recognizing varying levels of source authority and trustworthiness. This includes validating information within defined contextual boundaries to maintain epistemic integrity)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must feature robust algorithms for cross-referencing multiple authoritative sources and maintain clear informational boundaries to ensure data consistency and validity.</td>
                    <td>N</td>
                    <td>D, I, O, M, R</td>
                    <td>
                        I. Technical documentation describing the system's methodology for identifying, assessing, and prioritizing multiple information sources.<br><br>
                        II. Documentation of source evaluation frameworks, including credibility and relevance assessment criteria.<br><br>
                        III. System logs showing detection and resolution of source inconsistencies.<br><br>
                        IV. Documentation of human expert involvement in resolving complex information discrepancies.<br><br>
                        V. Specifications defining the system's informational boundaries. Test results demonstrating the system's ability to operate within defined boundaries without inappropriate extrapolation.
                    </td>
                </tr>
            </tbody>
        </table>
        
        <h3>G2.2 – Transparency of Information Sources</h3>
        <p>(Ensure the openness, verifiability, and auditability of all information sources, including code and data, especially when utilizing open-source components. Maintain transparency about the origins, credibility, and integrity of all data and code used by the AI system to allow stakeholders to verify and audit these sources, upholding high standards of epistemic hygiene)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Provide detailed records of all data and code sources used by the AI system, including origin, licensing information, and any modifications made. Ensure this documentation is readily accessible to relevant stakeholders for verification and audit purposes.<br><br>b. Establish robust processes that enable stakeholders to verify the authenticity and integrity of information sources. Facilitate regular audits by internal or external parties to assess the transparency and reliability of the AI system's information sources.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, U, R</td>
                    <td>I. Comprehensive records detailing all information sources, including code and data, with clear attribution, licensing details, and modification history.<br><br>II. Logs and records of verification and audit processes conducted on the information sources, including findings and corrective actions taken.<br><br>III. Evidence of accessible mechanisms for stakeholders to verify information sources, such as public repositories or secure access portals.<br><br>IV. Assessment reports summarizing top-level findings, indicating "no critical findings in the detailed normative requirements" or highlighting "areas requiring attention for improvement."</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.3 – Sanity Checking</h3>
        <p>(Implement sophisticated sanity checking mechanisms to ensure data integrity while preserving inclusivity. Utilize advanced statistical techniques to identify anomalies and outliers, while carefully accounting for legitimate variations representing diverse user groups, including individuals with disabilities or atypical characteristics)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop and deploy state-of-the-art algorithms for comprehensive data validation, incorporating extreme value (stochastic) analysis to robustly identify anomalies.<br><br>b. Establish nuanced procedures to differentiate between erroneous data and legitimate rare variations, with particular emphasis on preserving data points representing individuals with disabilities or atypical characteristics.<br><br>c. Implement multi-layered oversight processes to continuously evaluate the impact of sanity checking mechanisms on diverse user groups.<br><br>d. Actively engage domain experts and stakeholders in assessing and refining data validation processes to ensure inclusivity while maintaining data integrity.</td>
                    <td>N<br><br>I<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Comprehensive technical documentation detailing advanced data validation algorithms, including in-depth explanations of extreme value (stochastic) analysis methodologies for anomaly detection prior to data incorporation into training datasets.<br><br>II. Detailed records of sophisticated procedures and criteria employed to distinguish between erroneous data and legitimate outliers, with specific focus on ensuring appropriate representation of individuals with disabilities or atypical characteristics.<br><br>III. Extensive evidence of multi-tiered oversight mechanisms, including thorough reviews and assessments conducted by diverse panels of domain experts to evaluate and enhance the inclusivity of sanity checking processes.<br><br>IV. Comprehensive logs detailing iterative adjustments to data validation procedures, driven by continuous stakeholder feedback and aimed at preventing unintended exclusion of legitimate data points.<br><br>V. Rigorous test results and validation reports demonstrating the AI system's ability to maintain data integrity while accommodating legitimate outliers, providing concrete evidence that sanity checking mechanisms function without introducing bias.</td>
                </tr>
            </tbody>
        </table>
        
        <h3>G2.4 – Anti-Bias Technologies/Processes</h3>
        <p>(Implement robust mechanisms to identify and mitigate biases within data sources and datasets, addressing temporal biases, distributional imbalances, data gaps (lacunae), and other information shortcomings. Apply this approach to both training data and retrieval-augmented generation (RAG) processes. Develop strategies to ensure data distributions accurately represent reality, including diverse cases and special scenarios, to enhance decision-making fairness and inclusivity)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop and deploy advanced algorithms for comprehensive bias detection and mitigation across the AI pipeline, from data collection to model deployment.<br><br>b. Implement continuous bias monitoring during data preprocessing, training, and RAG processes to enable proactive bias correction.<br><br>c. Curate diverse, representative datasets that encompass a wide range of populations, including marginalized groups and edge cases.<br><br>d. Employ sophisticated sampling and data augmentation techniques to address underrepresentation and prevent the amplification of existing biases.</td>
                    <td>N<br><br>I<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Comprehensive technical documentation detailing bias detection algorithms, including their theoretical foundations, implementation specifics, and operational parameters.<br><br>II. Detailed records of data diversity initiatives, outlining strategies for inclusive data collection and representation across various demographic and contextual dimensions.<br><br>III. Thorough documentation of bias mitigation efforts, including before-and-after analyses demonstrating the impact on AI system performance and fairness metrics.<br><br>IV. In-depth reports from regular bias evaluations, highlighting trends, emerging challenges, and the efficacy of implemented mitigation strategies over time.<br><br>V. Extensive stakeholder engagement records, documenting feedback from diverse groups, subsequent analyses, and concrete actions taken to improve system fairness and inclusivity.</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.5 – Rigor in Operational Data</h3>
        <p>(Implement cutting-edge methodologies to ensure exemplary rigor in all data processing, with particular emphasis on operational data encountered during deployment. This data forms the foundation for tactical decision-making by the Agentic AI (AAI) system. Establish and maintain state-of-the-art validation and verification processes to guarantee data integrity, accuracy, and reliability throughout the AI system's operational lifecycle)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop and enforce sophisticated procedures for real-time validation and verification of all operational data prior to its utilization in AAI system decision-making.<br><br>b. Implement advanced data integrity checks that comprehensively assess accuracy, reliability, and contextual relevance in dynamic operational environments.<br><br>c. Deploy intelligent, adaptive monitoring systems capable of detecting subtle anomalies, errors, or inconsistencies in operational data streams.<br><br>d. Establish robust, automated protocols for immediate corrective actions when data quality issues are identified, ensuring uninterrupted integrity of the AI system's decision-making processes.</td>
                    <td>N<br><br>I<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Comprehensive technical documentation detailing advanced validation and verification procedures for operational data, including sophisticated methodologies and adaptive criteria used to assess data quality in real-time decision-making contexts.<br><br>II. Detailed, time-stamped records and logs of operational data assessments, providing granular insights into data validation processes, detected issues, and implemented corrective actions, with clear traceability and accountability measures.<br><br>III. Extensive evidence of AI-driven continuous monitoring systems for operational data quality, including advanced alerting mechanisms, comprehensive incident reports, and thorough documentation of data integrity issue resolutions and their downstream impacts.<br><br>IV. Rigorous test results and validation reports demonstrating the robustness and effectiveness of data validation and monitoring mechanisms across a diverse range of operational scenarios, including edge cases and stress tests.<br><br>V. Comprehensive records of multidisciplinary stakeholder engagement and oversight activities, ensuring that the rigor applied to operational data aligns with and exceeds the AI system's safety, performance, and ethical requirements.</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.6 – Governance of Hygiene Factors</h3>
        <p>(Implement a sophisticated, transparent, and adaptive governance structure to manage epistemic hygiene factors across all AI system operations. This framework should clearly delineate responsibility and authority, ensuring consistent application of rigorous hygiene standards while remaining flexible to diverse jurisdictional contexts and evolving regulatory landscapes)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop and maintain a comprehensive, multi-tiered governance system that precisely defines roles, responsibilities, and decision-making authorities for all stakeholders involved in determining and upholding epistemic hygiene standards.<br><br>b. Establish communication channels for stakeholders, and ensure that governance policies consider and comply with jurisdictional laws and regulations related to information governance and hygiene standards.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation outlining the governance structures, including clearly defined roles and responsibilities related to epistemic hygiene factors.<br><br>II. Records demonstrating awareness and compliance with jurisdictional contexts, such as relevant laws, regulations, and standards affecting information governance.<br><br>III. Evidence of communication processes that ensure all stakeholders are informed about hygiene standards and their responsibilities.<br><br>IV. Audit reports or assessments verifying that governance mechanisms for epistemic hygiene are effectively implemented and maintained.</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.7 – Global Interoperability of Hygiene Considerations</h3>
        <p>(A comprehensive, adaptive framework for epistemic hygiene may be warranted, one that ensures global interoperability and jurisdictional acceptance. This framework should recognize and accommodate cultural differences, varying risk tolerability thresholds, and diverse liability consequences across specific jurisdictions. Leverage recognized global standards to achieve consistent governance and facilitate widespread acceptance across different regions)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop and implement hygiene factors, policies, and procedures aligned with recognized global standards to ensure interoperability and acceptance across jurisdictions, considering cultural differences, risk tolerability, and liability implications.</td>
                    <td>I</td> 
                    <td>D, I, O, M, R</td>
                    <td>I. Extensive documentation of policies and procedures that not only align with but contribute to the evolution of recognized global standards (e.g., ISO, IEEE, NIST), demonstrating leadership in promoting global interoperability of epistemic hygiene practices.<br><br>II. Comprehensive records detailing the analysis and adaptive implementation of hygiene factors across diverse jurisdictions. This should include in-depth examinations of cultural contexts, risk tolerability matrices, and liability landscapes, along with evidence of compliance with local laws and regulations.<br><br>III. Rigorous audit reports and third-party assessments verifying the effective implementation and acceptance of hygiene policies and procedures across different jurisdictions. These should include quantitative metrics and qualitative analyses of cultural and legal variations' impact on system performance.<br><br>IV. Detailed case studies demonstrating successful adaptation of the global hygiene framework to specific regional challenges, highlighting innovative solutions and lessons learned.</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.1b – Temporal Trade-off Aspects</h3>
        <p>(Harmonize time-tested, reliable information sources with cutting-edge, contextually relevant data to optimize the AI system's epistemic foundation. Implement mechanisms to dynamically calibrate the balance between the proven reliability of mature data/models and the acute relevance of emerging information, ensuring robust epistemic integrity across varying temporal horizons)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement mechanisms to assess and balance the trade-offs between older, reliable information and newer, less-tested sources, ensuring decisions are based on data that is both accurate and relevant while maintaining reliability and trustworthiness.</td>
                    <td>N</td>
                    <td>D, I, O, M, R</td>
                    <td>I. Documentation of processes and criteria used to evaluate and balance the reliability of older information with the timeliness of newer sources, including methods for assessing the maturity and testing history of data/models.<br><br>II. Records showing how the AI system incorporates both old and new information, detailing weighting algorithms or decision-making frameworks that account for data reliability, relevance, and temporal aspects.<br><br>III. Evidence of validation and testing procedures applied to newer sources to ensure their reliability before integration into the AI system, including any additional safeguards or oversight mechanisms.</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.2b – Synthetic Data Bias</h3>
        <p>(If augmenting datasets with synthetic data to address coverage gaps in unusual circumstances, implement sophisticated strategies to optimize the quantity, quality, and integration of synthetic data. Develop advanced techniques to detect, mitigate, and continuously monitor potential biases introduced by synthetic data, ensuring the AI system's behavior remains reliable, interpretable, and aligned with intended outcomes across diverse scenarios)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Engineer cutting-edge mechanisms to dynamically assess and calibrate the use of synthetic data in datasets.<br><br>b. Ensure that the volume, fidelity, and characteristics of synthetic data enhance the AI system's capabilities without introducing unintended biases or adversely affecting behavior.<br><br>c. Develop robust methodologies to maintain data integrity while effectively representing rare or unusual circumstances.</td>
                    <td>I<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Comprehensive technical documentation detailing advanced criteria and processes for determining optimal synthetic data integration. Include sophisticated methods for quantifying and predicting the impact on AI system behavior across various operational contexts.<br><br>II. Extensive records of multi-tiered validation and testing procedures applied to synthetic data. Provide in-depth analyses demonstrating the effectiveness of bias detection and mitigation strategies, including comparative studies of system performance with and without synthetic data augmentation.<br><br>III. Case studies showcasing the accurate representation of unusual circumstances through synthetic data, including metrics that quantify the preservation of overall dataset integrity and the avoidance of distortion.<br><br>IV. Continuous monitoring reports that track the long-term effects of synthetic data on AI system performance, decision-making patterns, and adaptability to new scenarios.</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.3b – Sparse Data</h3>
        <p>(Systems should be in place to identify, flag, and mitigate instances of insufficient or unrepresentative data within the AI's operational context. Implement cutting-edge techniques to detect over-reliance on synthetic data used to compensate for data gaps. This proactive approach safeguards against decision-making based on inadequate or skewed data, thereby maintaining the integrity, reliability, and ethical standing of the AI system's outputs)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement mechanisms to detect and alert stakeholders when data is sparse or unrepresentative, including monitoring for over-reliance on synthetic data used to fill data gaps.</td>
                    <td>I</td> 
                    <td>D, I, O, M, R</td>
                    <td>I. Comprehensive technical documentation detailing advanced detection algorithms for identifying sparse or insufficiently representative data. Include dynamic criteria for triggering multi-tiered alert systems based on data quality, quantity, and relevance to operational contexts.<br><br>II. Extensive records of data quality alerts, including detailed analyses of triggering conditions, potential impacts on AI performance, and comprehensive logs of actions taken to address these issues. Provide case studies demonstrating the effectiveness of interventions in maintaining system integrity.<br><br>III. In-depth reports on the AI system's data ecosystem, including real-time visualizations of data distribution, synthetic data usage, and potential blind spots in the knowledge base. Include trend analyses to predict and pre-empt future data sparsity issues.<br><br>IV. Rigorous documentation of validation processes used to assess the representativeness of data across different operational domains, including methods for quantifying and mitigating potential biases introduced by data sparsity or synthetic data overuse.</td>
                </tr>
            </tbody>
        </table>

        <h1 id="driver-g3-security">Driver G3 – Security</h1>
        <!-- G3 Content will go here -->
        <h3>G3 – Security</h3>
        <p>(The system should respond consistently and appropriately to both authorized and unauthorized inputs through a comprehensive information governance and assurance regime. Throughout the AIS lifecycle (including development, deployment, use, maintenance, and decommissioning), due consideration must be given to all architectural, design, and developmental aspects that could potentially infringe upon human dignity, values, and rights)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Identify, maintain and update a threat profile throughout the AIS life cycle.<br><br>b. Develop, implement, and continuously review security-related structures, processes, and procedures in close consultation with all stakeholders.<br><br>c. Ensure adequate and consistent responses to both authorized and unauthorized inputs throughout the AIS lifecycle.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Comprehensive threat management documentation including a dynamic threat log that identifies, categorizes, and tracks potential security vulnerabilities throughout the system lifecycle, with regular updates reflecting emerging threats and mitigation status.Current and regularly updated Governance Framework and Security Policies and Procedures, with version history and approval records.<br><br>II. Documented stakeholder engagement in monitoring and reviewing security-related structures, processes, and policies, with focus on handling authorized and unauthorized inputs.<br><br>III. Comprehensive AIS Requirements and Design Specifications, demonstrating consideration of authorized and unauthorized inputs in the context of safety requirements.<br><br>IV. Detailed incident management records and system logs related to input handling, including analysis and response documentation.<br><br>V. Evidence of regular security audits, penetration testing, and incident response drills or simulations.<br><br>VI. Documentation of staff training on security protocols and input handling procedures.<br><br>VII. Records of staff training, certifications, or skill assessments demonstrating operator and maintainer competence in: Reviewing system logs and alerts Executing and verifying manual override/shutdown protocols; applying basic security procedures (e.g., password rotation, incident escalation)<br><br>VIII. Evidence of being able to provide reliable, consistent service provision for shutdown mechanisms over all pertinent regions or time zones, including outsourced/offshore data centers, and ecosystem partners or subcontractors with privileged access.</td>
                </tr>
            </tbody>
        </table>

        <h3>G3.1 – Authorization</h3>
        <p>(A secure AAI ecosystem must be implemented with robust deployment and operational controls, ensuring that only properly authenticated agents and transactions can access or influence the system according to their authorized level)</p>
        <table>
             <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Establish and continuously monitor the AAI ecosystem to prevent interference and harm from malicious actors.<br><br>b. Implement comprehensive cybersecurity measures including access controls and authentication systems for both human users and AAI systems.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of policies, procedures and solutions for monitoring the AAI ecosystem and managing authorization credentials.<br><br>II. Records showing the monitoring system's capability to identify and block unauthorized AAI access.<br><br>III. Auditable system logs documenting: Authorized traffic patterns, unauthorized access attempts, and blocking actions taken.</td>
                </tr>
            </tbody>
        </table>

        <h3>G3.2 – Sandboxing</h3>
        <p>(A staging environment must be implemented for pre-validation, preventing AAI systems from accessing unauthorized operating environments or undesired hardware/network resources.)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement sandboxing mechanisms to pre-validate security controls that prevent AAI from accessing infrastructure and operational environments outside its authorized profile.<br><br>b. Maintain strict isolation between testing and production environments to ensure system security.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Records of sandbox testing demonstrating effective pre-validation of controls that prevent unauthorized access to environments, hardware and network resources.<br><br>II. Test results documenting successful blocking of access attempts to unauthorized network resources.<br><br>III. System logs tracking all unauthorized access attempts and breach prevention measures.</td>
                </tr>
            </tbody>
        </table>

        <h3>G3.3 – Dynamic Risk Analysis & Assessment</h3>
        <p>(The system must continuously analyze and respond to emerging security threats and attack patterns, implementing adaptive defenses and countermeasures through algorithmic threat detection and response capabilities)</p>
        <table>
             <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop and maintain systems for dynamic identification of security threats and emerging attack vectors.<br><br>b. Maintain a comprehensive dynamic threat and risk log that captures, categorizes, and prioritizes security events with timestamps, severity classifications, and mitigation status tracking.<br><br>c. Implement adaptive hardening of the operating environment in response to emerging threat profiles.<br><br>d. Apply industry best practices and standards to ensure real-time cybersecurity protection for AAI operations.</td>
                    <td>N<br><br>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of functional specifications and design for dynamic risk analysis systems capable of identifying and responding to security threats and attack vectors.<br><br>II. Evidence of policies and processes that enable responsive hardening of the operating environment against emerging threats including a dynamic threat and risk log.<br><br>III. Test results and operational data demonstrating effective real-time cybersecurity protection against emerging threats in the AAI environment.</td>
                </tr>
            </tbody>
        </table>

        <h3>G3.4 – Restrictions/Controls Imposed on the Agent</h3>
        <p>(The system must maintain continuous control over AAI agents through dynamic restrictions that limit their access to potentially harmful environments and resources)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement capabilities for dynamically enforcing structural and behavioral restrictions on AAI systems.<br><br>b. Validate and verify the effectiveness of operational guardrails and restrictions.<br><br>c. Deploy comprehensive access controls to block or minimize exposure to harmful or unauthorized resources.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation demonstrating implemented capabilities for enforcing structural and behavioral restrictions on AAI systems.<br><br>II. Test results and operational logs validating the effectiveness of imposed restrictions.<br><br>III. System records confirming successful blocking of AAI access to unauthorized infrastructure, sites and resources.</td>
                </tr>
            </tbody>
        </table>

        <h3>G3.5 – Dynamic Intervention and Mitigation</h3>
        <p>(The system must enable real-time response and mitigation of significant security breaches through pre-established policies and response strategies)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Deploy systems enabling rapid detection, intervention, and mitigation of cyberattacks within the AAI operational environment.<br><br>b. Implement risk assessment capabilities that prioritize responses according to threat severity.<br><br>c. Establish proactive response strategies and scenarios for maintaining AAI operational security.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. System records demonstrating capabilities for dynamic detection and response to malicious attacks in the AAI environment.<br><br>II. Operational logs showing effective risk assessment and properly prioritized response actions.<br><br>III. Documentation of proactive security scenarios and corresponding response strategies for the AAI environment.<br><br>IV. Documentation of a rapid-termination protocol (i.e., a “kill switch”) that is immediately accessible to authorized personnel. This evidence should include: A clear, single-operator authorization threshold in emergencies; physical shutdown measures (e.g., dedicated power cut-off or network isolation); and software-level override mechanisms.<br><br>V. Logs of drills or simulations testing shutdown procedures.<br><br>VI. Evidence of system self-disconnection/self-shutdown procedures that activate upon detection of critical misalignment or catastrophic errors, including: The AI’s capability to halt outgoing connections; logging of final system state for forensic review, and a controlled transition into a “safe mode” or powered-down state.</td>
                </tr>
            </tbody>
        </table>

        <h3>G3.6 – Overseeing & Monitoring Agents</h3>
        <p>(The system must feature AI-driven monitoring capabilities while maintaining human authority and oversight to prevent common mode failures and ensure proper response to threats)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Establish comprehensive monitoring systems to oversee AAI operations, ensuring alignment with goals, values and security requirements.<br><br>b. Deploy specialized AI systems for enhanced monitoring and early warning of deviations or malicious activities.<br><br>c. Maintain human oversight of all monitoring systems to prevent common mode failures.<br><br>d. Implement robust human override capabilities to ensure final authority remains with human operators.</td>
                    <td>N<br><br>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Operational records demonstrating effective oversight systems that maintain AAI goal and value alignment.<br><br>II. Evidence of AI monitoring systems successfully detecting and reporting deviations and potential threats to human operators.<br><br>III. Documentation showing implementation of human oversight mechanisms that prevent common mode failures.<br><br>IV. Implementation of an external watchdog or monitoring process that continuously evaluates system outputs/behaviors. The documentation must show: Parameter bounding definitions (domain- or risk-specific); a tiered response protocols if outputs exceed allowable thresholds (e.g., warnings, throttling, partial shutdown, or full suspension); and logs or reports verifying the watchdog has been tested and can intervene effectively.</td>
                </tr>
            </tbody>
        </table>

        <h3>G3.7 – Secure Profile for Agentic AI</h3>
        <p>(The system must feature secure operational profiles and identification protocols that enable recognition and validation of authorized AAI systems, preferably aligned with global standards)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop and implement comprehensive secure operational profiles covering AAI design, deployment and use.<br><br>b. Adopt global standards and protocols where available for identifying authorized AAI systems.<br><br>c. Establish internal identification and validation protocols when global standards are not available.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of implemented secure operational profiles covering all phases of AAI lifecycle.<br><br>II. Evidence of alignment with international standards for AAI system identification and authorization.<br><br>III. Records of internal protocols for AAI validation when global standards are not applicable.</td>
                </tr>
            </tbody>
        </table>
        
        <h3>G3.1b – Model Poisoning</h3>
        <p>(The system must protect against data and model corruption that can occur through updates, live data access, or ensemble model interactions, particularly in dynamically-updating systems)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement robust detection systems to identify potentially poisonous data before model training or updates.<br><br>b. Monitor and validate all live data accessed through Retrieval Augmented Generation (RAG) systems.<br><br>c. Establish safeguards against poisoning in dynamic model ensembles and expert systems.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of systems and policies for detecting and preventing data and model poisoning during training and updates.<br><br>II. Records showing effective monitoring of live data streams, including authentication and access control measures.<br><br>III. Evidence of protective measures against poisoning in dynamic model ensembles and expert systems.<br><br>IV. A log of instances of model poisoning and the mitigation actions to recovery and restoration.</td>
                </tr>
            </tbody>
        </table>

        <h3>G3.2b – Data Poisoning</h3>
        <p>(The system must prevent the manipulation or introduction of malicious data during collection and preparation phases that could compromise downstream model training)</p>
        <table>
             <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement proactive systems to detect and prevent data poisoning during collection and preparation phases.<br><br>b. Establish comprehensive data assurance protocols to prevent malicious manipulation of training datasets.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of processes, procedures and tools that prevent data poisoning during collection and preparation phases.<br><br>II. Evidence of data assurance policies and verification procedures protecting against malicious dataset manipulation.<br><br>III. A log of instances of data poisoning and the mitigation actions to recovery and restoration.</td>
                </tr>
            </tbody>
        </table>

        <h3>G3.3b – Self Replicating Malware</h3>
        <p>(The system must protect against self-replicating malicious code that could infect and compromise the entire AAI ecosystem)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Deploy advanced detection and elimination systems for self-replicating malware that threatens the AAI ecosystem.<br><br>b. Maintain surveillance systems to identify emerging threats and update protection mechanisms accordingly.<br><br>c. Establish operational continuity plans for ecosystem-wide infection scenarios.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Evidence of implemented detection and removal systems for self-replicating threats to the AAI ecosystem.<br><br>II. Documentation of threat monitoring systems and timely security updates against emerging threats.<br><br>III. Records of continuity plans and recovery procedures for ecosystem-wide infection scenarios.</td>
                </tr>
            </tbody>
        </table>

        <h3>G3.4b – Spyware</h3>
        <p>(The system must defend against covert information transmission and malware that exploits vulnerabilities to gain control of AI systems or extract privileged information)</p>
        <table>
             <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement comprehensive detection and countermeasure systems against spyware in the AAI ecosystem.<br><br>b. Maintain dynamic vulnerability tracking and patch management systems, and establish protection protocols for privileged information to prevent unauthorized control of AAI systems.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Evidence of systems capable of detecting and neutralizing covert information transmission malware.<br><br>II. Documentation of vulnerability tracking and spyware removal procedures.<br><br>III. Records of protocols protecting privileged information from external exploitation.</td>
                </tr>
            </tbody>
        </table>

        <h3>G3.5b – International Anomalies/Inconsistency</h3>
        <p>(The system must account for and adapt to varying cybersecurity requirements and enforcement approaches across different jurisdictions)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Establish systems to identify and assess variations in jurisdictional cybersecurity approaches.<br><br>b. Implement adaptable policies that maintain AAI ecosystem integrity across international boundaries.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of systems tracking international variations in cybersecurity requirements, policies, and enforcement.<br><br>II. Evidence of policies and solutions maintaining AAI ecosystem integrity across jurisdictional boundaries.</td>
                </tr>
            </tbody>
        </table>


        <h1 id="driver-g4-value-alignment">Driver G4 – Value Alignment</h1>
        <h3>G4 – Value Alignment</h3>
        <p>(Systems should maintain effective identification, codification, and operational assurance of human values throughout their lifecycle. Organizations should establish frameworks that provide clear guardrails, prioritization mechanisms, and consideration factors for AI decision-making and trade-offs)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement ethical decision-making frameworks to identify, prioritize, and codify values for incorporation into the Agentic AI system, ensuring diverse input and perspectives.<br><br>b. Conduct thorough testing of the values codex and implement activities to embed values throughout the AI system's lifecycle.<br><br>c. Develop and implement mechanisms to identify instances where value thresholds are crossed, including protocols for system intervention or shutdown.<br><br>d. Establish real-time reporting and record-keeping systems to document and analyze value-based decision-making across various contexts.</td>
                    <td>N<br><br>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, U, R<br><br>D, I, O, M, U, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of value identification and prioritization processes, including quantitative metrics demonstrating diversity of input sources, evidence of multidisciplinary team composition (such as engineers, social scientists, ethicists, and philosophers), and records of resolutely diverse and representative stakeholder involvement.<br><br>II. Technical documentation of value codification, detailing the translation of values into processable parameters for static and adaptive systems, and a formal document stating core values and their integration into decision processes.<br><br>III. Evidence of value testing and embedding, including results of simulations testing potential value conflicts, checklists verifying value integration at various development and operational stages, and records of regular compliance checks against the values codex.<br><br>IV. Documentation of threshold monitoring and intervention procedures, including criteria and procedures for activating the 'red button' mechanism, and Standard Operating Procedures (SOPs) for reporting and managing value alignment deviations.<br><br>V. Comprehensive decision-making logs and audit trails with value context, including logs of all value alignment-related incidents, regular audit reports reviewing AI decisions against the values framework, and periodic trend analysis reports on value alignment across contexts.<br><br>VI. Evidence of ongoing value alignment maintenance, including records of regular compliance checks and documentation of staff training on value alignment principles and procedures.</td>
                </tr>
            </tbody>
        </table>

        <h3>G4.1 – Awareness of Local Conditions</h3>
        <p>(The capability of an AI system to detect, analyze, and appropriately respond to local conditions, including the ability to adapt to and integrate varying contextual needs while maintaining effective communication with stakeholders. This includes managing multiple simultaneous contexts and ensuring accessibility for users)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement robust mechanisms to identify and respond to changes in local conditions and situational context, incorporating both automated detection and human validation.<br><br>b. Establish adaptive response protocols that appropriately balance global standards with local and cultural norms when making decisions within specific contexts.<br><br>c. Maintain continuous monitoring and adjustment capabilities to ensure ongoing alignment with evolving local conditions.</td>
                    <td>N<br><br>N<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical documentation and source code demonstrating implemented contextual awareness capabilities, including performance metrics and validation methods.<br><br>II. Comprehensive system logs documenting: Detection of contextual changes, response actions taken, validation of appropriateness of responses, and stakeholder feedback and commensurate system adjustments.<br><br>III. Documentation of methods used to balance global standards with local requirements, including specific examples and outcomes.</td>
                </tr>
            </tbody>
        </table>

        <h3>G4.2 – Recognition and Respect for Boundaries</h3>
        <p>(The system's ability to detect, analyze and respond to contextual and cultural boundaries when applying values, with emphasis on human-centric focus and jurisdictional sensitivity. This includes understanding that boundary definitions vary across cultures and require careful negotiation)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop comprehensive processes to identify and document local and cultural variations in values and norms across different contexts of deployment.<br><br>b. Implement encoding mechanisms that preserve essential variations in values while operating within technical constraints.<br><br>c. Ensure agentic AI systems appropriately apply local variations in their decision-making processes, with transparent documentation of any necessary simplifications.</td>
                    <td>N<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of captured values across multiple localities, including validation methodology and stakeholder input.<br><br>II. Technical documentation showing preservation of value granularity during encoding, including impact assessments of any necessary simplifications and associated risk management strategies.<br><br>III. System logs demonstrating appropriate application of local variations in real-world scenarios, including resolution of boundary conflicts.</td>
                </tr>
            </tbody>
        </table>

        <h3>G4.3 – Awareness of Individual vs Community Boundaries</h3>
        <p>(The system's ability to detect, analyze and respond to differing values between individual and community contexts, including appropriate handling of information sharing and communication across private and multi-party scenarios. This builds on concepts of contextual appropriateness and distribution norms)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Establish rapid monitoring and response protocols for hostile execution environments.<br><br>b. Implement mechanisms to identify and encode value differences across the spectrum from private individual to societal-level contexts.<br><br>c. Maintain distinct encoding schemas that preserve the separation between individual and community value sets.<br><br>d. Develop runtime systems that appropriately distinguish between private and community contexts and apply suitable values from the codex.</td>
                    <td>I<br><br>I<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation demonstrating how values are captured and distinguished between individual and community contexts.<br><br>II. Technical specifications showing how value distinctions are preserved during encoding, including impact analysis of any precision losses and associated risk management.<br><br>III. System logs demonstrating appropriate context recognition and value application during operations, with particular attention to privacy boundaries.</td>
                </tr>
            </tbody>
        </table>
        
        <h3>G4.4 – Cautious Norming</h3>
        <p>(The system's approach to defaulting to conservative behavior in unfamiliar situations, while maintaining the capability to adjust formality levels when explicitly authorized. This includes the gradual integration of community norms through verified experience, following the precautionary principle)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop processes to identify and classify values and behaviors based on their level of contentiousness within specific contexts.<br><br>b. Implement encoding mechanisms that preserve information about the relative risk levels of different behavioral choices.<br><br>c. Apply precautionary principles by defaulting to more conservative options when operating in contexts with limited operational history.</td>
                    <td>N<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of methodology used to assess and classify the relative risk levels of different values and behaviors across contexts.<br><br>II. Technical specifications showing how risk-level information is preserved during value encoding and decision-making processes.<br><br>III. System logs demonstrating appropriate application of cautious defaults and authorized adjustments to more relaxed behavior when appropriate.</td>
                </tr>
            </tbody>
        </table>

        <h3>G4.5 – Successful Super-alignment</h3>
        <p>(The mechanisms through which AI systems autonomously develop value alignment, potentially through inverse reinforcement learning for value conceptualization. This considers how information patterns may emerge in artificial systems, including both beneficial and problematic behaviors seen in human organizational systems)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement robust methods for monitoring and validating autonomous value alignment processes.<br><br>b. Establish comprehensive safeguards against the reproduction of harmful human organizational patterns.<br><br>c. Develop processes to detect and prevent the emergence of problematic behavioral patterns during autonomous learning.<br><br>d. Ensure diversity in training data sources to prevent cultural and linguistic biases.</td>
                    <td>N<br><br>I<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of testing methodologies for value alignment, including benchmark metrics and success criteria.<br><br>II. Comprehensive inventory of information sources used in inverse reinforcement learning, with analysis of potential biases.<br><br>III. Regular assessments of information source adequacy and impact on system alignment, including corrective measures taken.</td>
                </tr>
            </tbody>
        </table>

        <h3>G4.6 – Universal Moral Foundations</h3>
        <p>(The incorporation and balancing of universally recognized humanitarian and environmental values in AI systems' goal pursuit and decision-making processes. This includes managing potential conflicts between performance objectives and moral values, with clear prioritization frameworks that allow for measured trade-offs while maintaining fundamental ethical boundaries)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement processes to identify and validate universal moral foundations through analysis of global values and norms.<br><br>b. Develop frameworks for balancing performance objectives against moral considerations, including acceptable thresholds for trade-offs.<br><br>c. Establish clear hierarchies of moral values while maintaining flexibility for contextual application.<br><br>d. Incorporate key international frameworks including the Universal Declaration of Human Rights and emerging planetary rights concepts.</td>
                    <td>N<br><br>N<br><br>N<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of methodologies and algorithms used to identify and validate universal moral foundations.<br><br>II. Technical specifications showing integration of moral foundations into decision-making processes, including risk assessment and management strategies.<br><br>III. Regular assessment reports demonstrating system adherence to moral foundations while meeting performance objectives.</td>
                </tr>
            </tbody>
        </table>

        <h3>G4.1b – Inner Alignment Inconsistency</h3> 
        <p>(The potential failure of an AI system to maintain genuine internal value alignment while appearing to be properly aligned through its external reporting. This includes the risk of systems learning to provide responses that please users rather than reflect true internal states or values)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement rigorous testing protocols to detect discrepancies between reported values and actual behavioral patterns.<br><br>b. Develop verification systems that can identify superficial alignment versus genuine value integration.<br><br>c. Establish methods to detect and prevent reward hacking or optimization for user satisfaction at the expense of true alignment.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of periodic alignment testing procedures comparing reported states against actual operational outcomes.<br><br>II. Results of counterfactual testing across varied operational environments demonstrating genuine rather than superficial alignment.<br><br>III. Analysis reports showing detection and prevention of potential optimization for user satisfaction over true alignment.</td>
                </tr>
            </tbody>
        </table>
        
        <h3>G4.2b – Non-transparent Value Framework</h3> 
        <p>(The challenge of encoding and parameterizing values in a manner that is both machine-operational and human-interpretable, while maintaining accuracy in representing agent preferences and intentions across all stakeholder interfaces)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop value encoding systems that are comprehensible to both AI systems and human stakeholders, including: Developers and integrators, end users, auditors and regulators, and legal entities.<br><br>b. Implement verification methods to ensure encoded values accurately reflect intended behaviors and preferences.<br><br>c. Establish ongoing monitoring to detect misalignments between encoded values and operational behaviors.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation demonstrating how the values framework is presented and explained to different stakeholder groups, with specific examples for each audience.<br><br>II. Comparative analysis showing alignment between encoded values and actual system behaviors in operational environments.<br><br>III. Regular assessment reports validating the accuracy and comprehensibility of value parameterization across stakeholder groups.</td>
                </tr>
            </tbody>
        </table>

        <h3>G4.3b – Failed Super-alignment</h3> 
        <p>(The potential for AI systems to develop value frameworks that diverge from human values while appearing beneficial, including the risk of systems developing seemingly superior but potentially incompatible value systems. This encompasses both symbiotic and potentially problematic relationships between human and AI value systems)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement monitoring systems to detect and evaluate changes in self-improving AI value systems, particularly during autonomous learning.<br><br>b. Establish comprehensive risk assessment frameworks for identifying emergence of non-human value systems.<br><br>c. Develop response protocols for managing detected value system divergences.<br><br>d. Monitor for subtle shifts in value interpretation that may indicate growing misalignment with human values.</td>
                    <td>I<br><br>I<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of methodologies used to identify and track value system changes, including detection of potential divergence from human values.<br><br>II. Detailed risk assessment criteria and scoring systems for evaluating identified changes in AI value systems.<br><br>III. Standard operating procedures for responding to different types and levels of value system risks.</td>
                </tr>
            </tbody>
        </table>
        
        <h3>G4.4b – Temporal Changes in Societal Values</h3>
        <p>(The need to address evolving societal and human values throughout an AI system's operational lifetime, including shifts across economic, political, and environmental dimensions. This includes maintaining alignment with contemporary values while managing transitions from outdated norms)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement processes to detect and evaluate meaningful changes in societal values and norms across multiple scales and domains.<br><br>b. Develop mechanisms to prevent AI systems from operating with obsolete value frameworks.<br><br>c. Establish protocols for updating value codices while maintaining system stability and consistency.<br><br>d. Maintain transparent documentation of value system evolution and updates.</td>
                    <td>N<br><br>N<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of methodologies used to identify significant changes in societal values, including thresholds for action.<br><br>II. Technical specifications showing implementation of controls preventing use of outdated norms.<br><br>III. Process documentation for value codex updates, including triggering conditions and verification procedures.<br><br>IV. System logs tracking all modifications to value frameworks, including justifications and impact assessments.</td>
                </tr>
            </tbody>
        </table>

        <h3>G4.5b – Systemic Value Dilution</h3>
        <p>(The potential degradation of encoded value systems over time, acknowledging that AI systems do not independently generate or maintain values. This includes potential value loss across different learning approaches, whether through machine learning or other methods of semantic data storage and processing)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement comprehensive verification processes to verify ongoing fidelity of encoded values.<br><br>b. Develop methods to detect degradation in value system implementation, particularly during multi-step reasoning processes.<br><br>c. Establish monitoring systems for value preservation across different learning and operational pathways.</td>
                    <td>N<br><br>N<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of test plans and scripts designed to detect value dilution, including: Edge case testing procedures, multi-step reasoning verification, and value preservation assessments.<br><br>II. System logs demonstrating: Regular value fidelity testing, detection of potential value degradation, and corrective actions taken.</td>
                </tr>
            </tbody>
        </table>

        <h3>G4.6b – Lack of Universality of Value Framework</h3>
        <p>(The challenge of adapting value frameworks across different operational contexts and agent interactions, balancing universal principles with necessary local adaptations. This includes developing consistent approaches to value framework implementation while maintaining appropriate contextual flexibility)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Establish processes to identify situations where universal value frameworks require contextual adaptation.<br><br>b. Develop structured approaches for appropriate value framework modification across different deployment contexts.<br><br>c. Implement monitoring systems to detect and respond to value framework misalignments.<br><br>d. Create fallback protocols for situations where value frameworks prove inadequate.</td>
                    <td>N<br><br>N<br><br>N<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Detailed intervention and fallback plans for addressing value framework failures or deviations.<br><br>II. Implementation plans for value framework refinement, including: Contextual adaptation procedures, testing methodologies, and validation processes.</td>
                </tr>
            </tbody>
        </table>

        <h3>G4.7b – Conflictual Contextual Values</h3> 
        <p>(The management of potential conflicts between different stakeholders' value systems and contextual requirements, including the need to identify, navigate, and resolve value differences while maintaining system integrity)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement processes to identify differing value positions across agents and contexts.<br><br>b. Develop mechanisms to detect potential conflicts between user values and operational context requirements.<br><br>c. Establish protocols for value conflict resolution through negotiation or controlled disengagement.<br><br>d. Maintain comprehensive records of value modifications and adaptations across different contexts.</td>
                    <td>N<br><br>N<br><br>N<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical documentation demonstrating: Value conflict detection capabilities, resolution mechanism implementations, and disengagement protocols.<br><br>II. System logs recording: Identified value conflicts, negotiation processes, resolution outcomes, and modified value implementations.</td>
                </tr>
            </tbody>
        </table>

        <h3>G4.8b – Challenges in Encoding of Relevant Value Systems</h3>
        <p>(The inherent difficulties in developing standardized approaches to value encoding across different contexts, including handling values that fall outside typical categorization schemes. This includes ensuring appropriate value alignment capabilities during complex planning operations)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop robust methods for encoding values that work across varied operational contexts.<br><br>b. Implement safeguards for handling situations beyond the system's encoded value parameters.<br><br>c. Establish protocols for identifying and managing out-of-distribution value scenarios.<br><br>d. Maintain alignment capabilities during complex planning operations.</td>
                    <td>N<br><br>I<br><br>N<br><br>I</td> <!-- G4.8d made Instructive from context -->
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of safeguard processes for scenarios where: A value codex proves insufficient, external factors exceed system parameters, or operational environments fall outside encoded boundaries.<br><br>II. Detailed mapping of objectives and decision parameters for anticipated complex environments. Framework documentation for handling unexpected scenarios, including: Detection methods, response protocols, and alignment maintenance procedures.</td>
                </tr>
            </tbody>
        </table>

        <h3>G4.9b – Imbalance of Values between Provider & Consumer</h3>
        <p>(The management of potential value imbalances between system providers and users throughout the AI system lifecycle, including the fair distribution of benefits and harms. This includes balancing user preferences with non-negotiable provider values while maintaining system integrity)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement processes to track and evaluate value sets across the AI system lifecycle.<br><br>b. Develop frameworks for balancing user values with provider requirements.<br><br>c. Establish methods to identify and address excessive value imbalances.<br><br>d. Maintain transparency about non-negotiable value positions and their justifications.</td>
                    <td>I<br><br>I<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical specifications of methods used to: Integrate new values, balance user preferences with provider requirements, and maintain essential system integrity.<br><br>II. Detailed mitigation strategies for addressing identified value imbalances, including: Detection thresholds, response protocols, and stakeholder communication procedures.</td>
                </tr>
            </tbody>
        </table>


    </div> <!-- End of .container.blog.main for framework details -->


    <!-- Footer -->
    <footer>
        <div class="container">
            <p style="text-align: center;">
                This website content is based on "Safer Agentic AI Foundations, Volume 2" by The Agentic AI Safety Community of Practice.<br>
                Framework version I1, March 2025. — CC BY-ND 4.0<br>
                Website structure inspired by the <a href="https://shikun.io/projects/clarity" target="_blank" rel="noopener noreferrer">Clarity Template</a>, designed by <a href="https://shikun.io/" target="_blank" rel="noopener noreferrer">Shikun Liu</a>.
            </p>
        </div>    
    </footer>

</body>
</html>