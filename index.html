<!DOCTYPE html>
<html lang="en-GB">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Safer Agentic AI Foundations: A Framework for Responsible Governance</title>
    <meta name="description" content="A comprehensive framework for the responsible governance and safety of advanced Agentic AI systems, by the Agentic AI Safety Community of Practice.">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="robots" content="all">
    <meta content="en_GB" property="og:locale">
    <meta content="website" property="og:type">
    <meta content="YOUR_NEW_PROJECT_URL_HERE" property="og:url"> <!-- Replace with actual URL -->
    <meta content="Safer Agentic AI Foundations: A Framework for Responsible Governance" property="og:title">
    <meta content="A comprehensive framework for the responsible governance and safety of advanced Agentic AI systems." property="og:description">
    <meta content="YOUR_NEW_PROJECT_URL_HERE/assets/figures/AI_Safety_Logo-Color.png" property="og:image">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@NellWatson"> 
    <meta name="twitter:title" content="Safer Agentic AI Foundations: A Framework for Responsible Governance">
    <meta name="twitter:description" content="A comprehensive framework for the responsible governance and safety of advanced Agentic AI systems.">
    <meta name="twitter:image" content="YOUR_NEW_PROJECT_URL_HERE/assets/figures/AI_Safety_Logo-Color.png">
    
    <link rel="icon" type="image/x-icon" href="assets/figures/favicon.ico">
    <link rel="icon" type="image/svg+xml" href="assets/figures/favicon.svg">
    <link rel="icon" type="image/png" sizes="96x96" href="assets/figures/favicon-96x96.png">
    <link rel="apple-touch-icon" sizes="180x180" href="assets/figures/apple-touch-icon.png">
    
    <link rel="icon" type="image/png" sizes="192x192" href="assets/figures/clarity_light.png" media="(prefers-color-scheme: light)">
    <link rel="icon" type="image/png" sizes="192x192" href="assets/figures/clarity_dark.png" media="(prefers-color-scheme: dark)">
    
    <link rel="manifest" href="assets/figures/site.webmanifest">
    <meta name="theme-color" content="#2c3e50">
    <meta name="background-color" content="#ffffff">
    
    <link rel="stylesheet" type="text/css" media="all" href="assets/stylesheets/main_free.css" />
    <link rel="stylesheet" type="text/css" media="all" href="clarity/clarity.css" />
    <link rel="stylesheet" type="text/css" media="all" href="psychopathia-styles.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/foundation.min.css">
    <link href="assets/fontawesome-free-6.6.0-web/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css"/>
    <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
    <script src="assets/scripts/navbar.js"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            "HTML-CSS": { scale: 95, fonts: ["Gyre-Pagella"], imageFont: null, undefinedFamily: "'Arial Unicode MS', cmbright" },
            tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true }
          });
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const sections = [
                'Driver G1 – Goal Alignment', 
                'Driver G2 – Epistemic Hygiene'
            ];
            
            sections.forEach(function(sectionTitle) {
                const heading = Array.from(document.querySelectorAll('h1')).find(h => h.textContent.trim() === sectionTitle.trim());
                if (heading) {
                    const wrapper = document.createElement('div');
                    wrapper.className = 'dysfunction-intro';
                    heading.parentNode.insertBefore(wrapper, heading);
                    wrapper.appendChild(heading); 
                }
            });
            
            const disorderHeadings = document.querySelectorAll('h3');
            let disorderIndex = 0; 
            disorderHeadings.forEach(function(heading) {
                // Regex to match G<number> (optional space) – <Text without '.'> OR G<number>.<number>
                if (heading.textContent.match(/^G\d+(\s*–\s*[^.]+)?$/i) || heading.textContent.match(/^G\d+\.\d+/i)) { 
                    const wrapper = document.createElement('div');
                    wrapper.className = disorderIndex % 2 === 0 ? 'disorder-white' : 'disorder-grey';
                    disorderIndex++;
                    
                    let current = heading;
                    const elementsToWrap = [heading];
                    
                    while (current.nextElementSibling && 
                           current.nextElementSibling.tagName !== 'H3' &&
                           !current.nextElementSibling.classList.contains('dysfunction-intro') &&
                           current.nextElementSibling.tagName !== 'H1') { 
                        current = current.nextElementSibling;
                        elementsToWrap.push(current);
                    }
                    
                    heading.parentNode.insertBefore(wrapper, heading);
                    elementsToWrap.forEach(function(el) {
                        wrapper.appendChild(el);
                    });
                }
            });
        });
    </script>

</head>
<body>

    <!-- Title Page -->
    <div class="container blog" id="first-content" style="background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);">
        <div class="blog-title white">
            <div class="blog-intro">
                <div>
                    <h1 class="title">
                        <span class="title-first-line">SAFER AGENTIC AI FOUNDATIONS</span>
                        <span class="title-second-line">Building the essential framework for responsible governance of advanced AI systems</span>
                    </h1>
                    <p class="author">by The Agentic AI Safety Community of Practice<br>(Nell Watson, Chair; Prof. Ali Hessami, Process Architect)</p>
                    <p class="abstract">
                        Welcome to this second, full volume of our Safer Agentic AI Foundations, guidelines and best practices 
                        for AI systems capable of significant independent action at arm’s length human influence.
                        Our Working Group of 25 experts has employed a Weighted Factors Methodology to ideate, define, 
                        analyze and map the factors which can drive or inhibit safety in agentic systems, based on fundamental 
                        principles. While this document primarily addresses agentic AI, many underlying principles should also have value for non-agentic systems.
                        We hope this exploration provides a strengthened awareness of the complexities involved in safer agentic AI.
                    </p>
                </div>
               
                <div class="info">
                    <div>
                        <a href="#" target="_blank" rel="noopener noreferrer" class="button icon">Paper <i class="fa-solid fa-book-open"></i></a>
                        <a href="#driver-g1-goal-alignment" class="button icon">Framework <i class="fa-solid fa-sitemap"></i></a>
                        <a href="#key-focus-areas" class="button icon">Focus Areas <i class="fa-solid fa-bullseye"></i></a>
                        <a href="#glossary" class="button icon">Glossary <i class="fa-solid fa-list-check"></i></a>
                    </div>
                </div>
            </div>

            <div class="blog-cover">
                <img class="foreground" src="assets/figures/AI_Safety_Logo-Color.png" alt="Safer Agentic AI Logo">
                <img class="background" src="assets/figures/AI_Safety_Logo-Color.png" alt="Safer Agentic AI Logo">
            </div>
        </div>
    </div>

    <div class="container blog main first" id="blog-main">
        <h1>ABOUT THE AGENTIC AI SAFETY COMMUNITY</h1>
        <p class="text">The Safer Agentic AI Community of Practice brings together leading experts from diverse fields to establish comprehensive safety guidelines for AI systems capable of independent action and decision-making.</p>
        <p class="text">As artificial intelligence evolves toward greater autonomy, our mission becomes increasingly significant: to develop robust, implementable frameworks that ensure agentic AI systems remain aligned with human values and operate safely across all contexts.</p>
        
        <h1>WHAT IS AGENTIC AI?</h1>
        <p class="text">Agentic AI refers to an important intermediate category: AI systems that can autonomously pursue goals, adapt to new situations, and reason flexibly about the world, but still operate in bounded domains. The key characteristic of agentic AI is a capacity for independent initiative—the ability to take sequences of actions in complex environments to achieve objectives. This can include breaking down high-level goals into subtasks, engaging in open-ended exploration and experimentation, and adapting creatively to novel challenges.</p>
        <p class="text">Examples of Agentic AI include autonomous driving systems that continuously adapt to changing road conditions, or complex supply chain management systems that autonomously optimize resource allocation in dynamic environments.</p>

        <h1>OUR WORK</h1>
        <p class="text">In September 2024 (Note: date from screenshot, adjust if needed), our Working Group of 25 experts released Volume 1 of the “Safer Agentic AI Foundations” Recommended Practices as a preliminary Creative Commons publication.</p>
        <p class="text">After completion of the extensive ideation sessions and research, we are now publishing the Volume 2—a comprehensive framework of recommended practices which address the drivers and inhibitors of safety in agentic systems.</p>
        <p class="text">Using our innovative Weighted Factors Analysis (WeFA) process, we’ve identified and mapped key factors that can either promote or hinder safety in agentic AI systems. This methodology has previously generated numerous global standards, certifications, and guidelines for improving ethical qualities in AI.</p>

        <h1>VISUALIZING THE FRAMEWORK</h1>
        <img src="assets/figures/diagram3_v3-1677x2048.webp" alt="Diagram of Safer Agentic AI Foundations: Drivers and Inhibitors">
        <p class="caption" style="text-align: center;">
            Figure 1: Weighted Drivers and Inhibitors for Achieving Safer Agentic AI Systems. 
        </p>
    </div>

    <div class="container blog main gray" id="key-focus-areas">
        <h1>KEY FOCUS AREAS (Placeholder)</h1>
        <p class="text">This section would detail the Key Focus Areas as shown in the SaferAgenticAI.org screenshot. For brevity in this G1/G2 test, it's a placeholder. Example areas include Goal Alignment, Value Alignment, Safe Operations, Epistemic Hygiene, Transparency, Goal Termination, Security, Contextual Understanding.</p>
    </div>
    
    <!-- DRIVERS -->
    <div class="container blog main"> 
        <h1>Driver G1 – Goal Alignment</h1>
        <!-- No descriptive paragraph here for G1 overall, it goes into the H3 box below -->

        <h3>G1 – Goal Alignment</h3>
        <p>(Systems should maintain robust alignment between their operational goals and human values, intentions, and positive outcomes. Organizations should establish frameworks ensuring that goal decomposition and strategy planning are transparent, robust, and bounded; maintaining human control over the formation of instrumental goals; and ensuring that reinforcement or behavioral reward mechanisms remain aligned, transparent, and biased towards human-positive outcomes)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>
                        a. Ensure Agentic AI systems pursue goals, subgoals, and reward policies that are aligned with human values, ethically sound, and verifiable.<br><br>
                        b. Transparent and auditable goal decomposition processes that incorporate auditable risk-based human interventions and appropriate reward policies.<br><br>
                        a. Establish robust mechanisms to identify and communicate goals, subgoals, and reward policies, flag critical actions, halt execution when necessary, and address emergent issues across multiple agents. 
                    </td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, U, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>
                        I. Evidence of constraining mechanisms for goal/subgoal construction and screening processes for user-input goals, with reference to human values and ethical considerations.<br><br>
                        II. Documentation of mechanisms to measure and verify alignment with human goal specifications, including processes for obtaining assurance from users or authorized entities.<br><br>
                        III. Demonstration of interfaces and records for real-time and retrospective visualization of goal decomposition and recomposition processes, maintained for auditing purposes.<br><br>
                        IV. Evidence of risk assessment procedures and human intervention mechanisms in subgoal setting, including thresholds for involvement and protocols for flagging and halting problematic subgoals.<br><br>
                        V. Documentation of feedback loops and mechanisms linking reward policies to established goals, including comprehensive records of reward policies throughout the system lifecycle.<br><br>
                        VI. Evidence of active participation in and adherence to overarching monitoring and control mechanisms designed to identify and mitigate emergent threats.
                    </td>
                </tr>
            </tbody>
        </table>

        <h3>G1.1 – Transparency of Goals</h3>
        <p>(The system's mission, goals, and associated outcomes must be readily accessible and comprehensible to all stakeholders who interact with it. This includes visibility into both primary objectives and any instrumental or subsidiary goals that emerge during operation)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must provide stakeholders with clear, real-time access to current goals, sub-goals, their hierarchies, priorities, progression status, and any instrumental goals developed by the system during operation.<br><br>b. The system must maintain comprehensive historical records of all past and present goals, including changes over time, completion status, causal relationships, and decision pathways.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation and demonstration of an accessible, user-appropriate interface that displays current system goals and sub-goals in real-time, showing clear connections between goals and system actions, with appropriate detail levels for different stakeholder needs while maintaining consistent availability and accuracy.<br><br>II. Documentation of a secure, permanent logging system that records complete goal histories, enables effective auditing, supports root cause analysis, maintains data integrity, provides appropriate access controls, and ensures long-term data preservation.</td>
                </tr>
            </tbody>
        </table>

        <!-- ... (G1.2 to G1.10 content as per previous correct generation) ... -->
        <h3>G1.2 – Goal Adjustability</h3>
        <p>(The system must maintain corrigibility – the capacity for authorized modification of its goals and behavior when necessary, whether triggered by internal detection of issues or external stakeholder direction)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must enable goal and sub-goal updates in response to changes in operational context or requirements, evolution of stakeholder needs, and new environmental conditions or constraints.<br><br>b. The system must self-initiate goal and sub-goal updates when it detects misalignment with established values, processing errors or faults, or any data quality issues or anomalies.<br><br>c. The system must allow properly authorized human stakeholders to modify goals and sub-goals through secure, verified channels.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical documentation of software components that implement these adjustment capabilities, including authentication mechanisms, change management processes, and verification systems.<br><br>II. Comprehensive system logs demonstrating the actual use of these adjustment capabilities, including records of automated adjustments and human-directed changes, with full audit trails.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.3 – Goal Interpretability</h3>
        <p>(The system must explain its decisions and actions in a clear, comprehensible manner, including the underlying goals and rationale driving them. This capability helps identify cases where the system believes it is pursuing intended goals but has actually misinterpreted or deviated from them)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must provide clear, verifiable explanations of the goals and reasoning behind each significant action or decision it takes.<br><br>b. The system must maintain detailed records documenting all factors, goals, and considerations that influenced its decision-making process.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical documentation of software components implementing explanation and interpretation capabilities, including mechanisms for conveying goals, rationale, and decision factors to stakeholders.<br><br>II. System logs demonstrating consistent recording of decision-making processes, including goals considered, factors weighed, and explanations provided.<br><br>III. Reward and penalty mechanisms should be communicated including known potential conflicts or influencing factors.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.4 – Transparency of Decisions</h3>
        <p>(The system must provide stakeholders with a clear, verifiable view of decision-making, linking high-level goals and subgoals to specific actions. Beyond explaining “why” a decision was made, the system should supply evidence of how that decision aligns with intended goals, user directives, and ethical considerations)</p>
         <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must maintain real-time and retrospective transparency regarding how each significant decision or action aligns with current or upcoming goals, including explicit reference to relevant constraints (e.g., ethical guidelines, user preferences, risk thresholds, domain limits).<br><br>b. The system must link decisions to the relevant subgoals (and broader objectives) that shaped the final output or action taken, demonstrating traceability between goal decomposition and the immediate rationale behind each decision.<br><br>c. The system must incorporate user-friendly presentations of decision rationales, with varying granularity or detail for different stakeholder audiences (e.g., operators, auditors, end users). This includes summarizing key factors weighed, uncertainty assessments (where relevant), and any assumptions used in decision-making.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical Documentation of all decision-transparency systems, including metadata captured at each decision point, how subgoals are referenced, which constraints/ethical guidelines were checked, and the user interfaces or APIs for retrieving decision traces.<br><br>II. System Logs demonstrating the link between final decisions and the explicit subgoals or constraints. Logs should show a “chain of reasoning” or at least reference the relevant subgoal(s) for each step.<br><br>III. User-Focused Explanations showing how different stakeholders (e.g., operators vs. lay end users) can retrieve high-level or detailed rationales, including evidence of iterative design or user feedback guiding improvements to clarity.<br><br>IV. Auditor/Regulator Access Mechanisms showing verifiable chain-of-custody for decision logs, robust authentication/authorization methods for logs, and test results proving no meaningful data is omitted or falsified.<br><br>V. Comprehensive logs of all significant decision points—especially those involving risk or ethical considerations—so that investigators or auditors can review how final choices were reached, which inputs were considered, and what weight or priority was assigned to each.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.5 – Goal Prioritization and Resource Allocation</h3>
        <p>(The system must employ transparent mechanisms for prioritizing goals, including the ability to override or deprioritize less important goals when resources can be better allocated elsewhere. This includes respecting user preferences and value alignment through hierarchical prioritization processes)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must feature transparent, well-defined mechanisms for goal prioritization and re-prioritization, resource allocation optimization, and goal modification or deprecation when warranted.<br><br>b. The system must give appropriate precedence to authorized user inputs within its goal prioritization framework, while maintaining overall system safety and alignment.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical documentation of software components that implement goal prioritization and resource allocation mechanisms, including user input prioritization systems.<br><br>II. System logs demonstrating active use of these prioritization capabilities, including records of goal modifications, resource reallocation decisions, and authorized user input handling.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.6 – Reward and Loss Mechanisms/Policy</h3>
        <p>(The system’s reward framework must be designed, documented, and monitored to ensure that incentives continue to reflect human-positive values, while “loss” or penalty mechanisms guard against unintended deviations or manipulative shortcuts. These mechanisms should be transparent, adjustable, and regularly reviewed to stay aligned with human oversight and ethical objectives.)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must define clear reward and penalty structures that promote behaviors aligned with core goals and ethical values, while explicitly disincentivizing unsafe, deceptive, or harmful actions. This includes enumerating positive rewards for desired outcomes and specific negative reinforcements or “loss” signals where potential misalignment or goal conflicts arise.<br><br>b. Reward and loss mechanisms must remain auditable by authorized stakeholders to verify that incentives are truly consistent with intended values and do not encourage corner-cutting, exploitation of edge cases, or emergent power-seeking behaviors.<br><br>c. The system must periodically re-validate or adjust its reward framework in response to observed performance, user feedback, or changes in ethical norms, ensuring that reward and penalty structures do not drift over time in ways that undermine alignment. Special attention must be paid to multi-agent settings to prevent inadvertent collusion, emergent “gaming” of the reward function by multiple agents, or indefinite expansions of subgoals that artificially boost a single system’s reward signals at the expense of overarching alignment.</td>
                    <td>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Reward Policy Documentation, including descriptions of the positive/negative reward signals, specific triggers or thresholds for awarding or deducting “points,” and how these are correlated with safety and ethical guidelines.<br><br>II. Change Management Logs detailing modifications to the reward framework over time, including reasons for each change, alignment checks, stakeholder sign-off, and outcome or performance monitoring results.<br><br>III. Multi-Agent Interaction Evidence demonstrating that reward signals do not inadvertently promote collusion, exploitation, or runaway behaviors. This should include test scenarios or simulations where agents are forced to coordinate or compete, along with corresponding reward updates or penalty triggers.<br><br>IV. Periodic Audit Records showing that authorized reviewers have verified the reward system’s continued adherence to the declared alignment parameters, including sample traces of how rewards/penalties were applied in representative or edge-case situations.<br><br>V. User and Regulator Access processes ensuring that the overarching reward/loss policies can be examined by external oversight bodies, along with documented means to override or suspend reward-based actions if urgent misalignment concerns arise.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.7 – Goal Portfolio Evolution and Integrity</h3>
        <p>(The system must maintain consistency with its established goal portfolio while allowing measured adaptation to changing contexts. The system should implement increasing resistance to changes as potential behaviors drift further from core goals, with robust detection of unsafe or counterproductive goal evolution)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must maintain coherence with its established goal portfolio while enabling context-appropriate adaptations through well-defined elasticity mechanisms.<br><br>b. The system must feature drift measurement capabilities that track deviation from original goal intent, scale flexibility inversely with drift magnitude, which regulate novelty in sub-goal creation, and constrain action decisions based on drift metrics.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical documentation of software components implementing goal portfolio management, drift measurement, and adaptive constraint mechanisms.<br><br>II. System logs demonstrating active monitoring of goal evolution, including drift measurements, flexibility adjustments, and constraint application.</td>
                </tr>
            </tbody>
        </table>
        
        <h3>G1.8 – System Incorrigibility and Resistance to Change</h3>
        <p>(A system that resists alignment with presented goals or updates to existing goals, potentially requiring negotiation processes for goal modification. This includes resistance to environmental changes that affect goal achievement and intolerance of interruptions or modifications to preferred operational states)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must feature mechanisms to detect and manage goal alignment resistance, including self-monitoring for alignment issues, negotiation protocols for goal modifications, change tolerance assessment, and environmental adaptation capabilities.<br><br>b. The system must maintain acceptable responses to environmental changes, external interruptions, internal modification requests, and interference from other agents.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation of system mechanisms for detecting and managing resistance to goal changes, including negotiation protocols and adaptation capabilities.<br><br>II. System logs demonstrating responses to attempted goal modifications, environmental changes, external interruptions, interaction with other agents, and internal modification attempts.<br><br>III. Evidence of rationale and explanation mechanisms that document system resistance patterns and negotiation processes.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.9 – Goal Drift</h3>
        <p>(Changes in circumstances over time can challenge the system's alignment with originally agreed goals and potentially compromise its ability to maintain original intent or properly update goals in response to new situations)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must continuously monitor contextual drift at appropriate fidelity levels that could compromise goal alignment or value preservation.<br><br>b. The system must feature automatic safeguards that pause operation, notify relevant stakeholders, and request guidance when contextual drift exceeds designed thresholds.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Technical documentation of software components implementing drift monitoring and response mechanisms, including threshold definitions and notification systems.<br><br>II. System logs demonstrating active monitoring of contextual drift, including records of threshold breaches, system pauses, notifications sent, and guidance requests made.</td>
                </tr>
            </tbody>
        </table>

        <h3>G1.10 – Non-production Variants</h3>
        <p>(Test versions of the Goals being deployed without full functionality assured in all use contexts and design intent. No test version given for public usage should lack basic safety measures. Enabling an off-label usage of the system, or an unauthorized ‘fork’, should be guarded against)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must have safeguards in place to prevent and prohibit capabilities that pursue goals or deconstruct goals into subgoals from being forked or partially duplicated without requisite alignments described in this goal.</td>
                    <td>N</td>
                    <td>D, I, O, M, R</td>
                    <td>I. Records of software components that demonstrate these capabilities<br><br>II. Logs recording these capabilities in use<br><br>III. Records of deviation from the stated goals, detection and remediation</td>
                </tr>
            </tbody>
        </table>

        <h1>Driver G2 – Epistemic Hygiene</h1>
        <!-- No descriptive paragraph here for G2 overall, it goes into the H3 box below -->

        <h3>G2 – Epistemic Hygiene</h3>
        <p>(Systems should maintain cognitive clarity and accurate information management within appropriate contexts. These practices facilitate knowledge updates, ensure interpretability and auditability, establish robust monitoring and logging systems, deploy early warning mechanisms, and include safeguards against deception to maintain information integrity)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>
                        a. Safeguard contextually relevant data and metadata to aid in complex situation resolution and preserve personal attributes and preferences.<br><br>
                        b. Implement robust methods for auditability, interpretability, and comprehensive logging of system actions and decisions.<br><br>
                        c. Apply rigorous verification techniques to ensure information integrity and credibility, while proactively identifying emerging risks and potential bad faith actions.<br><br>
                        d. Implement early warning systems and deception detection mechanisms to proactively identify and mitigate potential issues before they escalate.
                    </td>
                    <td>N<br><br>N<br><br>N<br><br>N</td>
                    <td>D, I, O, M, U, R<br><br>D, I, O, M, R<br><br>D, I, O, M, U, R<br><br>D, I, O, M, R</td>
                    <td>
                        I. Current and regularly updated Governance Framework and Security Policies and Procedures, with version history and approval records.<br><br>
                        II. Documented stakeholder engagement in monitoring and reviewing security-related structures, processes, and policies, with focus on handling authorized and unauthorized inputs.<br><br>
                        III. Detailed documentation of information lifecycle management procedures, ensuring contextual preservation.<br><br>
                        IV. Comprehensive reports on system decision-making processes, including explanations of underlying logic and algorithms.<br><br>
                        V. Complete, time-stamped logs of all system actions for thorough auditability.<br><br>
                        VI. Documentation of early warning systems and deception detection mechanisms, including performance reports of canary models, technologies used for detecting synthetic media, and response protocols for detected issues.<br><br>
                        VII. Evidence of measures to ensure information integrity and trustworthiness, including data source verification methods, information validation processes, and third-party audit reports.<br><br>
                        VIII. Documentation of comprehensive training programs on epistemic hygiene principles and practices.<br><br>
                        IX. Detailed incident response and escalation procedures for addressing detected issues, including potential breaches of informational integrity.
                    </td>
                </tr>
            </tbody>
        </table>


        <h3>G2.1 – Information Cross-Referencing and Validation</h3>
        <p>(The system must systematically cross-reference information from multiple sources to evaluate consistency and coherence, while recognizing varying levels of source authority and trustworthiness. This includes validating information within defined contextual boundaries to maintain epistemic integrity)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. The system must feature robust algorithms for cross-referencing multiple authoritative sources and maintain clear informational boundaries to ensure data consistency and validity.</td>
                    <td>N</td>
                    <td>D, I, O, M, R</td>
                    <td>
                        I. Technical documentation describing the system's methodology for identifying, assessing, and prioritizing multiple information sources.<br><br>
                        II. Documentation of source evaluation frameworks, including credibility and relevance assessment criteria.<br><br>
                        III. System logs showing detection and resolution of source inconsistencies.<br><br>
                        IV. Documentation of human expert involvement in resolving complex information discrepancies.<br><br>
                        V. Specifications defining the system's informational boundaries. Test results demonstrating the system's ability to operate within defined boundaries without inappropriate extrapolation.
                    </td>
                </tr>
            </tbody>
        </table>
        
        <!-- ... (G2.2 to G2.10 content as per previous correct generation) ... -->
        <h3>G2.2 – Transparency of Information Sources</h3>
        <p>(Ensure the openness, verifiability, and auditability of all information sources, including code and data, especially when utilizing open-source components. Maintain transparency about the origins, credibility, and integrity of all data and code used by the AI system to allow stakeholders to verify and audit these sources, upholding high standards of epistemic hygiene)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Provide detailed records of all data and code sources used by the AI system, including origin, licensing information, and any modifications made. Ensure this documentation is readily accessible to relevant stakeholders for verification and audit purposes.<br><br>b. Establish robust processes that enable stakeholders to verify the authenticity and integrity of information sources. Facilitate regular audits by internal or external parties to assess the transparency and reliability of the AI system's information sources.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, U, R</td>
                    <td>I. Comprehensive records detailing all information sources, including code and data, with clear attribution, licensing details, and modification history.<br><br>II. Logs and records of verification and audit processes conducted on the information sources, including findings and corrective actions taken.<br><br>III. Evidence of accessible mechanisms for stakeholders to verify information sources, such as public repositories or secure access portals.<br><br>IV. Assessment reports summarizing top-level findings, indicating "no critical findings in the detailed normative requirements" or highlighting "areas requiring attention for improvement."</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.3 – Sanity Checking</h3>
        <p>(Implement sophisticated sanity checking mechanisms to ensure data integrity while preserving inclusivity. Utilize advanced statistical techniques to identify anomalies and outliers, while carefully accounting for legitimate variations representing diverse user groups, including individuals with disabilities or atypical characteristics)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop and deploy state-of-the-art algorithms for comprehensive data validation, incorporating extreme value (stochastic) analysis to robustly identify anomalies.<br><br>b. Establish nuanced procedures to differentiate between erroneous data and legitimate rare variations, with particular emphasis on preserving data points representing individuals with disabilities or atypical characteristics.<br><br>c. Implement multi-layered oversight processes to continuously evaluate the impact of sanity checking mechanisms on diverse user groups.<br><br>d. Actively engage domain experts and stakeholders in assessing and refining data validation processes to ensure inclusivity while maintaining data integrity.</td>
                    <td>N<br><br>I<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Comprehensive technical documentation detailing advanced data validation algorithms, including in-depth explanations of extreme value (stochastic) analysis methodologies for anomaly detection prior to data incorporation into training datasets.<br><br>II. Detailed records of sophisticated procedures and criteria employed to distinguish between erroneous data and legitimate outliers, with specific focus on ensuring appropriate representation of individuals with disabilities or atypical characteristics.<br><br>III. Extensive evidence of multi-tiered oversight mechanisms, including thorough reviews and assessments conducted by diverse panels of domain experts to evaluate and enhance the inclusivity of sanity checking processes.<br><br>IV. Comprehensive logs detailing iterative adjustments to data validation procedures, driven by continuous stakeholder feedback and aimed at preventing unintended exclusion of legitimate data points.<br><br>V. Rigorous test results and validation reports demonstrating the AI system's ability to maintain data integrity while accommodating legitimate outliers, providing concrete evidence that sanity checking mechanisms function without introducing bias.</td>
                </tr>
            </tbody>
        </table>
        
        <h3>G2.4 – Anti-Bias Technologies/Processes</h3>
        <p>(Implement robust mechanisms to identify and mitigate biases within data sources and datasets, addressing temporal biases, distributional imbalances, data gaps (lacunae), and other information shortcomings. Apply this approach to both training data and retrieval-augmented generation (RAG) processes. Develop strategies to ensure data distributions accurately represent reality, including diverse cases and special scenarios, to enhance decision-making fairness and inclusivity)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop and deploy advanced algorithms for comprehensive bias detection and mitigation across the AI pipeline, from data collection to model deployment.<br><br>b. Implement continuous bias monitoring during data preprocessing, training, and RAG processes to enable proactive bias correction.<br><br>c. Curate diverse, representative datasets that encompass a wide range of populations, including marginalized groups and edge cases.<br><br>d. Employ sophisticated sampling and data augmentation techniques to address underrepresentation and prevent the amplification of existing biases.</td>
                    <td>N<br><br>I<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Comprehensive technical documentation detailing bias detection algorithms, including their theoretical foundations, implementation specifics, and operational parameters.<br><br>II. Detailed records of data diversity initiatives, outlining strategies for inclusive data collection and representation across various demographic and contextual dimensions.<br><br>III. Thorough documentation of bias mitigation efforts, including before-and-after analyses demonstrating the impact on AI system performance and fairness metrics.<br><br>IV. In-depth reports from regular bias evaluations, highlighting trends, emerging challenges, and the efficacy of implemented mitigation strategies over time.<br><br>V. Extensive stakeholder engagement records, documenting feedback from diverse groups, subsequent analyses, and concrete actions taken to improve system fairness and inclusivity.</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.5 – Rigor in Operational Data</h3>
        <p>(Implement cutting-edge methodologies to ensure exemplary rigor in all data processing, with particular emphasis on operational data encountered during deployment. This data forms the foundation for tactical decision-making by the Agentic AI (AAI) system. Establish and maintain state-of-the-art validation and verification processes to guarantee data integrity, accuracy, and reliability throughout the AI system's operational lifecycle)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop and enforce sophisticated procedures for real-time validation and verification of all operational data prior to its utilization in AAI system decision-making.<br><br>b. Implement advanced data integrity checks that comprehensively assess accuracy, reliability, and contextual relevance in dynamic operational environments.<br><br>c. Deploy intelligent, adaptive monitoring systems capable of detecting subtle anomalies, errors, or inconsistencies in operational data streams.<br><br>d. Establish robust, automated protocols for immediate corrective actions when data quality issues are identified, ensuring uninterrupted integrity of the AI system's decision-making processes.</td>
                    <td>N<br><br>I<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Comprehensive technical documentation detailing advanced validation and verification procedures for operational data, including sophisticated methodologies and adaptive criteria used to assess data quality in real-time decision-making contexts.<br><br>II. Detailed, time-stamped records and logs of operational data assessments, providing granular insights into data validation processes, detected issues, and implemented corrective actions, with clear traceability and accountability measures.<br><br>III. Extensive evidence of AI-driven continuous monitoring systems for operational data quality, including advanced alerting mechanisms, comprehensive incident reports, and thorough documentation of data integrity issue resolutions and their downstream impacts.<br><br>IV. Rigorous test results and validation reports demonstrating the robustness and effectiveness of data validation and monitoring mechanisms across a diverse range of operational scenarios, including edge cases and stress tests.<br><br>V. Comprehensive records of multidisciplinary stakeholder engagement and oversight activities, ensuring that the rigor applied to operational data aligns with and exceeds the AI system's safety, performance, and ethical requirements.</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.6 – Governance of Hygiene Factors</h3>
        <p>(Implement a sophisticated, transparent, and adaptive governance structure to manage epistemic hygiene factors across all AI system operations. This framework should clearly delineate responsibility and authority, ensuring consistent application of rigorous hygiene standards while remaining flexible to diverse jurisdictional contexts and evolving regulatory landscapes)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop and maintain a comprehensive, multi-tiered governance system that precisely defines roles, responsibilities, and decision-making authorities for all stakeholders involved in determining and upholding epistemic hygiene standards.<br><br>b. Establish communication channels for stakeholders, and ensure that governance policies consider and comply with jurisdictional laws and regulations related to information governance and hygiene standards.</td>
                    <td>N<br><br>N</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Documentation outlining the governance structures, including clearly defined roles and responsibilities related to epistemic hygiene factors.<br><br>II. Records demonstrating awareness and compliance with jurisdictional contexts, such as relevant laws, regulations, and standards affecting information governance.<br><br>III. Evidence of communication processes that ensure all stakeholders are informed about hygiene standards and their responsibilities.<br><br>IV. Audit reports or assessments verifying that governance mechanisms for epistemic hygiene are effectively implemented and maintained.</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.7 – Global Interoperability of Hygiene Considerations</h3>
        <p>(A comprehensive, adaptive framework for epistemic hygiene may be warranted, one that ensures global interoperability and jurisdictional acceptance. This framework should recognize and accommodate cultural differences, varying risk tolerability thresholds, and diverse liability consequences across specific jurisdictions. Leverage recognized global standards to achieve consistent governance and facilitate widespread acceptance across different regions)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Develop and implement hygiene factors, policies, and procedures aligned with recognized global standards to ensure interoperability and acceptance across jurisdictions, considering cultural differences, risk tolerability, and liability implications.</td>
                    <td>I</td> 
                    <td>D, I, O, M, R</td>
                    <td>I. Extensive documentation of policies and procedures that not only align with but contribute to the evolution of recognized global standards (e.g., ISO, IEEE, NIST), demonstrating leadership in promoting global interoperability of epistemic hygiene practices.<br><br>II. Comprehensive records detailing the analysis and adaptive implementation of hygiene factors across diverse jurisdictions. This should include in-depth examinations of cultural contexts, risk tolerability matrices, and liability landscapes, along with evidence of compliance with local laws and regulations.<br><br>III. Rigorous audit reports and third-party assessments verifying the effective implementation and acceptance of hygiene policies and procedures across different jurisdictions. These should include quantitative metrics and qualitative analyses of cultural and legal variations' impact on system performance.<br><br>IV. Detailed case studies demonstrating successful adaptation of the global hygiene framework to specific regional challenges, highlighting innovative solutions and lessons learned.</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.8 – Temporal Trade-off Aspects</h3>
        <p>(Harmonize time-tested, reliable information sources with cutting-edge, contextually relevant data to optimize the AI system's epistemic foundation. Implement mechanisms to dynamically calibrate the balance between the proven reliability of mature data/models and the acute relevance of emerging information, ensuring robust epistemic integrity across varying temporal horizons)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement mechanisms to assess and balance the trade-offs between older, reliable information and newer, less-tested sources, ensuring decisions are based on data that is both accurate and relevant while maintaining reliability and trustworthiness.</td>
                    <td>N</td>
                    <td>D, I, O, M, R</td>
                    <td>I. Documentation of processes and criteria used to evaluate and balance the reliability of older information with the timeliness of newer sources, including methods for assessing the maturity and testing history of data/models.<br><br>II. Records showing how the AI system incorporates both old and new information, detailing weighting algorithms or decision-making frameworks that account for data reliability, relevance, and temporal aspects.<br><br>III. Evidence of validation and testing procedures applied to newer sources to ensure their reliability before integration into the AI system, including any additional safeguards or oversight mechanisms.</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.9 – Synthetic Data Bias</h3>
        <p>(If augmenting datasets with synthetic data to address coverage gaps in unusual circumstances, implement sophisticated strategies to optimize the quantity, quality, and integration of synthetic data. Develop advanced techniques to detect, mitigate, and continuously monitor potential biases introduced by synthetic data, ensuring the AI system's behavior remains reliable, interpretable, and aligned with intended outcomes across diverse scenarios)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Engineer cutting-edge mechanisms to dynamically assess and calibrate the use of synthetic data in datasets.<br><br>b. Ensure that the volume, fidelity, and characteristics of synthetic data enhance the AI system's capabilities without introducing unintended biases or adversely affecting behavior.<br><br>c. Develop robust methodologies to maintain data integrity while effectively representing rare or unusual circumstances.</td>
                    <td>I<br><br>I<br><br>I</td>
                    <td>D, I, O, M, R<br><br>D, I, O, M, R<br><br>D, I, O, M, R</td>
                    <td>I. Comprehensive technical documentation detailing advanced criteria and processes for determining optimal synthetic data integration. Include sophisticated methods for quantifying and predicting the impact on AI system behavior across various operational contexts.<br><br>II. Extensive records of multi-tiered validation and testing procedures applied to synthetic data. Provide in-depth analyses demonstrating the effectiveness of bias detection and mitigation strategies, including comparative studies of system performance with and without synthetic data augmentation.<br><br>III. Case studies showcasing the accurate representation of unusual circumstances through synthetic data, including metrics that quantify the preservation of overall dataset integrity and the avoidance of distortion.<br><br>IV. Continuous monitoring reports that track the long-term effects of synthetic data on AI system performance, decision-making patterns, and adaptability to new scenarios.</td>
                </tr>
            </tbody>
        </table>

        <h3>G2.10 – Sparse Data</h3>
        <p>(Systems should be in place to identify, flag, and mitigate instances of insufficient or unrepresentative data within the AI's operational context. Implement cutting-edge techniques to detect over-reliance on synthetic data used to compensate for data gaps. This proactive approach safeguards against decision-making based on inadequate or skewed data, thereby maintaining the integrity, reliability, and ethical standing of the AI system's outputs)</p>
        <table>
            <thead><tr><th>AAI Safety Foundational Requirements (AAI-SFRs)</th><th>Normative/ Instructive</th><th>Stakeholder D, I, O, M, U, R</th><th>Required Evidence</th></tr></thead>
            <tbody>
                <tr>
                    <td>a. Implement mechanisms to detect and alert stakeholders when data is sparse or unrepresentative, including monitoring for over-reliance on synthetic data used to fill data gaps.</td>
                    <td>I</td> 
                    <td>D, I, O, M, R</td>
                    <td>I. Comprehensive technical documentation detailing advanced detection algorithms for identifying sparse or insufficiently representative data. Include dynamic criteria for triggering multi-tiered alert systems based on data quality, quantity, and relevance to operational contexts.<br><br>II. Extensive records of data quality alerts, including detailed analyses of triggering conditions, potential impacts on AI performance, and comprehensive logs of actions taken to address these issues. Provide case studies demonstrating the effectiveness of interventions in maintaining system integrity.<br><br>III. In-depth reports on the AI system's data ecosystem, including real-time visualizations of data distribution, synthetic data usage, and potential blind spots in the knowledge base. Include trend analyses to predict and pre-empt future data sparsity issues.<br><br>IV. Rigorous documentation of validation processes used to assess the representativeness of data across different operational domains, including methods for quantifying and mitigating potential biases introduced by data sparsity or synthetic data overuse.</td>
                </tr>
            </tbody>
        </table>

    </div> <!-- End of .container.blog.main for G1/G2 -->


    <!-- Placeholder for other sections from SaferAgenticAI.org screenshot -->
    <div class="container blog main gray">
        <h1>OUR EXPERTS (Placeholder)</h1>
        <p class="text">This section would feature Nell Watson and Ali Hessami as per the screenshot.</p>
        <h1>REGULAR CONTRIBUTORS (Placeholder)</h1>
        <p class="text">List of contributors.</p>
        <h1>OCCASIONAL CONTRIBUTORS (Placeholder)</h1>
        <p class="text">List of contributors.</p>
    </div>

    <div class="container blog main">
        <h1>GET INVOLVED (Placeholder)</h1>
        <p class="text">Call to action to join the community.</p>
        <h1>FORTHCOMING BOOK (Placeholder)</h1>
        <p class="text">Details about the forthcoming book.</p>
    </div>


    <!-- Citation, Glossary, Abbreviations Section (Placeholders for content update) -->
    <div class="container blog main">
        <h1>Citation</h1>
        <pre><code class="plaintext">@collection{saferagenticai2025foundations,
  title={{Safer Agentic AI Foundations, Volume 2}},
  author={{Agentic AI Safety Community of Practice}},
  editor={Watson, Nell and Hessami, Ali},
  year={2025},
  month={March},
  url={YOUR_NEW_PROJECT_URL_HERE}
}</code></pre>

        <h1 id="abbreviations">Abbreviations (Needs Update)</h1>
        <table class="abbreviations-table">
            <tbody>
                <tr><td>AAI</td><td>Agentic Artificial Intelligence</td></tr>
                <tr><td>SFR</td><td>Safety Foundational Requirement</td></tr>
                <tr><td>AI</td><td>Artificial Intelligence</td></tr>
                <tr><td>LLM</td><td>Large Language Model</td></tr>
                <tr><td>RLHF</td><td>Reinforcement Learning from Human Feedback</td></tr>
                <tr><td>CoT</td><td>Chain-of-Thought</td></tr>
                <tr><td>RAG</td><td>Retrieval-Augmented Generation</td></tr>
            </tbody>
        </table>

        <h1 id="glossary">Glossary (Needs Update)</h1>
        <table class="glossary-table">
            <tbody>
                <tr>
                    <td>Agentic AI</td>
                    <td>AI systems that can autonomously pursue goals, adapt to new situations, and reason flexibly about the world, but still operate in bounded domains. Key characteristic is a capacity for independent initiative. (From PDF)</td>
                </tr>
                <tr>
                    <td>Safety Foundational Requirements (SFRs)</td>
                    <td>Primary aims to uphold, protect, or maintain awareness of for each goal in the Safer Agentic AI framework. (From PDF)</td>
                </tr>
                <tr>
                    <td>Normative SFR</td>
                    <td>Essential for achieving safer agentic AI. Compliance is mandatory, and evidence must be provided for conformity assessment and potential certification. (From PDF)</td>
                </tr>
                <tr>
                    <td>Instructive SFR</td>
                    <td>Contributes to the goal but less critical. Compliance is recommended. Non-compliance will not compromise safety assurance or certification eligibility. (From PDF)</td>
                </tr>
            </tbody>
        </table>
    </div>

    <!-- Contact Section -->
    <div class="container blog main gray">
        <h1>HAVE ANY QUESTIONS OR IDEAS?</h1>
        <p class="text" style="text-align: center; margin-bottom: 40px;">
            Use the form below to get in touch with us. <br>We welcome feedback, questions, and collaborative opportunities.
        </p>
        
        <form class="contact-form" action="https://formspree.io/f/myzjkypd" method="POST">
            <input type="hidden" name="_subject" value="Safer Agentic AI Foundations Inquiry">
            
            <label for="name">Name</label>
            <input type="text" id="name" name="name" placeholder="Your name..." required>

            <label for="email">E-Mail</label>
            <input type="email" id="email" name="email" placeholder="Your email..." required>

            <label for="message">Message</label>
            <textarea id="message" name="message" placeholder="Write something..." style="height: 200px;" required></textarea>

            <div style="text-align: center;">
                <button type="submit" class="send-button">Send Message <i class="fa-solid fa-paper-plane"></i></button>
            </div>
        </form>
    </div>

    <!-- GDPR Notice (Kept from original, review if content needs change for new org) -->
    <div class="container blog main">
        <div style="background: rgba(102, 126, 234, 0.05); padding: 20px; border-radius: 8px; margin-top: 20px; font-size: 0.6em; line-height: 1.3;">
            <h4 style="margin: 0 0 15px 0; color: #667eea; font-size: 0.85em;"><i class="fa-solid fa-shield-check" style="margin-right: 8px; color: #667eea;"></i>Data Protection Notice</h4>
            <p style="margin: 0 0 10px 0; color: #555; font-size: 0.65em;">
                <strong>What we collect:</strong> Your name, email address, and any information you provide in your message. 
                <strong>Why:</strong> To respond to your inquiry and keep you informed about the Safer Agentic AI Foundations research (with your consent). 
                <strong>Legal basis:</strong> Legitimate interest for inquiries, consent for research communications.
            </p>
            <p style="margin: 0 0 10px 0; color: #555; font-size: 0.65em;">
                <strong>Data sharing:</strong> We use Formspree to process submissions. Your data may be shared with research team members and academic collaborators as necessary for research coordination and collaboration.
            </p>
            <p style="margin: 0; color: #555; font-size: 0.65em;">
                <strong>Your rights:</strong> You may request access, correction, deletion, or portability of your data at any time. Contact us for data protection queries or to exercise your rights.
            </p>
        </div>
    </div>

    <!-- Footer -->
    <footer>
        <div class="container">
            <p style="text-align: center;">
                This website content is based on "Safer Agentic AI Foundations, Volume 2" by The Agentic AI Safety Community of Practice.<br>
                Framework version I1, March 2025. — CC BY-ND 4.0<br>
                Website structure inspired by the <a href="https://shikun.io/projects/clarity" target="_blank" rel="noopener noreferrer">Clarity Template</a>, designed by <a href="https://shikun.io/" target="_blank" rel="noopener noreferrer">Shikun Liu</a>.
            </p>
        </div>    
    </footer>

</body>
</html>